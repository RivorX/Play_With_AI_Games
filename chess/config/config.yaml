# ==============================================================================
# CHESS AI CONFIGURATION - OPTIMIZED FOR RTX 5060Ti 16GB v3.1-Fast
# ==============================================================================

# ------------------------------------------------------------------------------
# FILE PATHS
# ------------------------------------------------------------------------------
paths:
  data_dir: "data"
  models_dir: "models"
  logs_dir: "logs"
  
  # Best models (single file, overwritten when improved)
  best_model_il: "models/best_model_il.pt"
  best_model_rl: "models/best_model_rl.pt"
  
  # Checkpoint directories (saved every N epochs/iterations)
  il_checkpoints_dir: "models/IL"
  rl_checkpoints_dir: "models/RL"


# ------------------------------------------------------------------------------
# DATA PROCESSING
# ------------------------------------------------------------------------------
data:
  min_elo: 1800              # Minimum Elo rating for games (lowered for more data)
  max_games: 100000          # Top N games to use (sorted by avg Elo, best first)
  train_split: 0.9           # Train/validation split ratio
  max_moves_per_game: 200    # Skip longer games
  
  # Quality filtering
  select_top_games: true     # Sort by Elo and take top max_games (higher quality)
  sort_by_avg_elo: true      # Sort by average Elo of both players
  
  # Parallel processing (one process per PGN file)
  parallel_pgn_processing: true   # Process multiple PGN files in parallel
  max_workers: null               # null = auto-detect CPU count, or set manually


# ------------------------------------------------------------------------------
# MODEL ARCHITECTURE 
# ------------------------------------------------------------------------------
model:
  # Base architecture
  num_residual_blocks: 6     # Number of residual blocks (6-12 optimal)
  filters: 128               # Convolutional filters (128-256 for RTX 5060 Ti)
  policy_head_filters: 32    # Policy head filters
  value_head_filters: 32     # Value head filters
  value_hidden_dim: 256      # Value head hidden dimension
  dropout: 0.3               # Dropout rate

  history_positions: 4       # Number of previous positions to include
  
  # Advanced features (minimal params, significant quality gains)
  use_se_blocks: true           # üß† Channel attention (with mixed pooling v3.1)
  use_se2d_blocks: true         # üÜï v3.1: SE-Net v2 with spatial info (+0.5-1%, +5% time)
  use_spatial_attention: true   # üëÅÔ∏è Spatial attention
  spatial_attention_mode: 'last_2' # 'all', 'last_2', 'last_3', 'none'
  
  drop_path_rate: 0.1           # üé≤ Stochastic Depth (0% params, +4% quality)
  activation: 'relu'            # ‚ö° ReLU activation (5-10x FASTER than ELU!)
  use_coord_conv: true          # üó∫Ô∏è Position-aware conv (+0.5% params, +4% quality)
  
  # Advanced architectural features
  use_layer_scale: true         # LayerScale for better training stability (+0% params)
  layer_scale_init: 1e-5        # Initial LayerScale value (1e-6 to 1e-4)
  
  use_factorized_conv: true     # Factorized 3x3 convs (1x3 + 3x1, -30% params, ~same quality)
  use_adaptive_policy_pool: true # Adaptive pooling in policy head (+2-3% accuracy, 0% params)

  # Multi-Task Learning
  use_multitask_learning: true        # Enable auxiliary tasks
  win_prediction_weight: 0.3          # Weight for win prediction task
  material_prediction_weight: 0.2     # Weight for material count task
  check_prediction_weight: 0.15       # Weight for check prediction task


# ------------------------------------------------------------------------------
# IMITATION LEARNING (IL)
# ------------------------------------------------------------------------------
imitation_learning:
  # Training hyperparameters
  batch_size: 4096           # Batch size (doubled for better GPU utilization)
  learning_rate: 0.0014      # Learning rate (scaled with batch size)
  epochs: 100                # Maximum training epochs
  weight_decay: 0.0001       # L2 regularization
  grad_clip: 1.0             # Gradient clipping threshold
  
  # Advanced training features
  label_smoothing: 0.1       # Label smoothing (0.0 = off, 0.1 = standard)
  use_onecycle_lr: true      # üìà OneCycleLR scheduler for better convergence
  
  # Loss weights
  policy_loss_weight: 1.0    # Policy loss weight
  value_loss_weight: 0.5     # Value loss weight
  
  # Evaluation & checkpointing
  eval_every: 1              # Evaluate every N epochs
  checkpoint_every: 5        # Save checkpoint every N epochs
  
  # Early stopping
  max_patience: 15           # ‚ÑπÔ∏è Stop if no improvement for N epochs
  min_delta: 0.001           # Minimum improvement threshold


# ------------------------------------------------------------------------------
# REINFORCEMENT LEARNING (RL)
# ------------------------------------------------------------------------------
reinforcement_learning:
  # üöÄ Self-play configuration (PARALLEL)
  use_prioritized_replay: true        # Enable prioritized experience replay (default: false)
  games_per_iteration: 2048    # ‚¨áÔ∏è Reduced for faster iterations (adjust based on CPU)
  iterations: 1000           # Total RL iterations
  self_play_workers: 4       # üöÄ Parallel game workers (Windows: CPU only, Linux: can use GPU)
  
  # üöÄ Batch self-play mode
  use_batch_selfplay: true         # üöÄ NEW: Play multiple games simultaneously (5-10x faster)
  batch_games_per_worker: 512       # üöÄ NEW: Games per worker in batch mode (adjust for VRAM)

  # üÜï TEMPERATURE SCHEDULE
  use_temperature_schedule: true      # Enable adaptive temperature
  temperature_start: 1.5              # High exploration at start
  temperature_end: 0.5                # Lower exploration at end
  temperature_decay_iterations: 500   # Decay over N iterations

  # üöÄ MCTS parameters (BATCH OPTIMIZED)
  mcts_simulations: 100      # Number of MCTS simulations per move
  mcts_batch_size: 256       # Batch MCTS evaluations (32-128 optimal)
  mcts_reuse_tree: true      # Reuse tree across moves (faster, better)
  mcts_c_puct: 1.5           # Exploration constant (UCB)
  mcts_temperature: 1.0      # Temperature for move selection
  mcts_temperature_threshold: 15  # Move number to reduce temperature
  mcts_dirichlet_alpha: 0.3  # Dirichlet noise alpha
  mcts_dirichlet_weight: 0.25  # Weight of Dirichlet noise
  
  # Training parameters
  batch_size: 4096           # Training batch size (GPU)
  learning_rate: 0.0002       # Learning rate
  weight_decay: 0.05         # L2 regularization (AdamW)
  grad_clip: 0.5             # Gradient clipping
  train_epochs_per_iteration: 3  # ‚¨áÔ∏è Reduced from 5 (faster iteration)
  replay_buffer_size: 500000  # Max positions in replay buffer
  
  # Evaluation
  eval_games: 30             # ‚¨áÔ∏è Reduced from 20 (faster eval)
  eval_every: 2              # Evaluate every N iterations
  win_rate_threshold: 0.53   # Win rate to update best model
  checkpoint_every: 10        # Save checkpoint every N iterations
  
  # Loss weights
  policy_loss_weight: 1.0    # Policy loss weight
  value_loss_weight: 1.0     # Value loss weight


# ------------------------------------------------------------------------------
# HARDWARE & OPTIMIZATION
# ------------------------------------------------------------------------------
hardware:
  device: "cuda"             # Device: cuda, cpu, or mps (Mac)
  
  # Performance optimizations
  use_amp: true              # üöÄ Mixed Precision Training (~2x speedup)
  use_bfloat16: true         # üíæ bfloat16 instead of float16 (better range)
  num_workers: 4             # CPU workers for data loading
  prefetch_factor: 4         # DataLoader prefetch factor
  pin_memory: true           # Faster GPU data transfer


# ------------------------------------------------------------------------------
# LOGGING
# ------------------------------------------------------------------------------
logging:
  log_level: "INFO"          # DEBUG, INFO, WARNING, ERROR
  tensorboard: true          # Enable TensorBoard logging
  print_every: 10            # Print stats every N batches


# ------------------------------------------------------------------------------
# üÜï DEBUG & PROFILING
# ------------------------------------------------------------------------------
debug:
  enabled: false                    # Master switch for debug mode
  profile_training: true           # Time breakdown per epoch
  log_gpu_memory: false             # GPU memory usage
  profile_every_n_epochs: 1         # Profile frequency (if enabled)


# ------------------------------------------------------------------------------
# REPRODUCIBILITY
# ------------------------------------------------------------------------------
seed: 42                     # Random seed