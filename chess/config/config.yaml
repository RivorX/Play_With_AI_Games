# ==============================================================================
# CHESS AI CONFIGURATION - OPTIMIZED FOR RTX 5060 Ti
# ==============================================================================

# ------------------------------------------------------------------------------
# FILE PATHS
# ------------------------------------------------------------------------------
paths:
  data_dir: "data"
  models_dir: "models"
  logs_dir: "logs"
  
  # Best models (single file, overwritten when improved)
  best_model_il: "models/best_model_il.pt"
  best_model_rl: "models/best_model_rl.pt"
  
  # Checkpoint directories (saved every N epochs/iterations)
  il_checkpoints_dir: "models/IL"
  rl_checkpoints_dir: "models/RL"


# ------------------------------------------------------------------------------
# DATA PROCESSING
# ------------------------------------------------------------------------------
data:
  min_elo: 1800              # Minimum Elo rating for games (lowered for more data)
  max_games: 100000          # Top N games to use (sorted by avg Elo, best first)
  train_split: 0.9           # Train/validation split ratio
  max_moves_per_game: 200    # Skip longer games
  
  # Quality filtering
  select_top_games: true     # Sort by Elo and take top max_games (higher quality)
  sort_by_avg_elo: true      # Sort by average Elo of both players
  
  # Parallel processing (one process per PGN file)
  parallel_pgn_processing: true   # Process multiple PGN files in parallel
  max_workers: null               # null = auto-detect CPU count, or set manually


# ------------------------------------------------------------------------------
# MODEL ARCHITECTURE
# ------------------------------------------------------------------------------
model:
  # Base architecture
  num_residual_blocks: 10     # Number of residual blocks (6-12 optimal)
  filters: 192               # Convolutional filters (128-256 for RTX 5060 Ti)
  policy_head_filters: 32    # Policy head filters
  value_head_filters: 32     # Value head filters
  value_hidden_dim: 256      # Value head hidden dimension
  dropout: 0.3               # Dropout rate
  
  # Advanced features (minimal params, significant quality gains)
  use_se_blocks: true           # üß† Channel attention (+5% params, +20% quality)
  use_spatial_attention: true   # üëÅÔ∏è Spatial attention (+1% params, +6% quality)
  drop_path_rate: 0.1           # üé≤ Stochastic Depth (0% params, +4% quality)
  activation: 'elu'             # ‚ö° ELU activation (0% params, +3% quality)
  use_coord_conv: true          # üó∫Ô∏è Position-aware conv (+0.5% params, +4% quality)


# ------------------------------------------------------------------------------
# IMITATION LEARNING (IL)
# ------------------------------------------------------------------------------
imitation_learning:
  # Training hyperparameters
  batch_size: 4096           # Batch size (doubled for better GPU utilization)
  learning_rate: 0.0014      # Learning rate (scaled with batch size)
  epochs: 100                # Maximum training epochs
  weight_decay: 0.0001       # L2 regularization
  grad_clip: 1.0             # Gradient clipping threshold
  
  # Advanced training features
  label_smoothing: 0.1       # Label smoothing (0.0 = off, 0.1 = standard)
  use_onecycle_lr: true      # üìà OneCycleLR scheduler for better convergence
  
  # Loss weights
  policy_loss_weight: 1.0    # Policy loss weight
  value_loss_weight: 0.5     # Value loss weight
  
  # Evaluation & checkpointing
  eval_every: 1              # Evaluate every N epochs
  checkpoint_every: 5        # Save checkpoint every N epochs
  
  # Early stopping
  max_patience: 15           # ‚ÑπÔ∏è Stop if no improvement for N epochs
  min_delta: 0.001           # Minimum improvement threshold


# ------------------------------------------------------------------------------
# REINFORCEMENT LEARNING (RL) - üöÄ OPTIMIZED FOR RTX 5060 Ti
# ------------------------------------------------------------------------------
reinforcement_learning:
  # üöÄ Self-play configuration (PARALLEL)
  games_per_iteration: 16    # ‚¨áÔ∏è Reduced for faster iterations (adjust based on CPU)
  iterations: 1000           # Total RL iterations
  self_play_workers: 4       # üöÄ Parallel game workers (Windows: CPU only, Linux: can use GPU)
  
  # üöÄ MCTS parameters (BATCH OPTIMIZED)
  mcts_simulations: 50       # ‚¨áÔ∏è Reduced from 100 (faster, still effective)
  mcts_batch_size: 64        # üöÄ NEW: Batch MCTS evaluations (32-128 optimal)
  mcts_c_puct: 1.5           # Exploration constant (UCB)
  mcts_temperature: 1.0      # Temperature for move selection
  mcts_temperature_threshold: 15  # Move number to reduce temperature
  mcts_dirichlet_alpha: 0.3  # Dirichlet noise alpha
  mcts_dirichlet_weight: 0.25  # Weight of Dirichlet noise
  
  # Training parameters
  batch_size: 2048           # Training batch size (GPU)
  learning_rate: 0.001       # Learning rate
  weight_decay: 0.01         # L2 regularization (AdamW)
  grad_clip: 1.0             # Gradient clipping
  train_epochs_per_iteration: 3  # ‚¨áÔ∏è Reduced from 5 (faster iteration)
  replay_buffer_size: 50000  # Max positions in replay buffer
  
  # Evaluation
  eval_games: 10             # ‚¨áÔ∏è Reduced from 20 (faster eval)
  eval_every: 5              # Evaluate every N iterations
  win_rate_threshold: 0.55   # Win rate to update best model
  checkpoint_every: 5        # Save checkpoint every N iterations
  
  # Loss weights
  policy_loss_weight: 1.0    # Policy loss weight
  value_loss_weight: 1.0     # Value loss weight


# ------------------------------------------------------------------------------
# HARDWARE & OPTIMIZATION
# ------------------------------------------------------------------------------
hardware:
  device: "cuda"             # Device: cuda, cpu, or mps (Mac)
  
  # Performance optimizations
  use_amp: true              # üöÄ Mixed Precision Training (~2x speedup)
  use_bfloat16: true         # üíæ bfloat16 instead of float16 (better range)
  num_workers: 12            # CPU workers for data loading
  pin_memory: true           # Faster GPU data transfer


# ------------------------------------------------------------------------------
# LOGGING
# ------------------------------------------------------------------------------
logging:
  log_level: "INFO"          # DEBUG, INFO, WARNING, ERROR
  tensorboard: true          # Enable TensorBoard logging
  print_every: 10            # Print stats every N batches

# ------------------------------------------------------------------------------
# REPRODUCIBILITY
# ------------------------------------------------------------------------------
seed: 42                     # Random seed