import os
import yaml
import time
import numpy as np
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
import cv2
from stable_baselines3 import PPO
import torch
from pathlib import Path
import easyocr

# Wczytaj konfiguracjƒô
script_dir = os.path.dirname(os.path.abspath(__file__))
config_path = os.path.join(script_dir, '..', 'config', 'config.yaml')
with open(config_path, 'r') as f:
    config = yaml.safe_load(f)

agario_dir = os.path.abspath(os.path.join(script_dir, '..'))
models_dir = os.path.join(agario_dir, config['paths']['models_dir'])

def find_available_models():
    """Znajd≈∫ wszystkie dostƒôpne modele w folderze models/"""
    if not os.path.exists(models_dir):
        return []
    
    models = []
    for file in os.listdir(models_dir):
        if file.endswith('.zip'):
            model_path = os.path.join(models_dir, file)
            # Pobierz info o pliku
            size_mb = os.path.getsize(model_path) / (1024 * 1024)
            modified = os.path.getmtime(model_path)
            modified_str = time.strftime('%Y-%m-%d %H:%M', time.localtime(modified))
            
            models.append({
                'name': file,
                'path': model_path,
                'size_mb': size_mb,
                'modified': modified_str
            })
    
    # Sortuj po dacie modyfikacji (najnowsze pierwsze)
    models.sort(key=lambda x: os.path.getmtime(x['path']), reverse=True)
    return models

def select_model():
    """Interaktywny wyb√≥r modelu"""
    print("\n" + "="*60)
    print("AGAR.IO MODEL TESTER")
    print("="*60)
    
    models = find_available_models()
    
    if not models:
        print(f"\n‚ùå Brak modeli w folderze: {models_dir}")
        print("   Najpierw wytrenuj model u≈ºywajƒÖc: python agario/scripts/train.py")
        return None
    
    print(f"\nüìÅ Znaleziono {len(models)} model(i):\n")
    
    for i, model in enumerate(models, 1):
        print(f"  [{i}] {model['name']}")
        print(f"      Rozmiar: {model['size_mb']:.2f} MB")
        print(f"      Zmodyfikowano: {model['modified']}")
        print()
    
    while True:
        try:
            choice = input(f"Wybierz model (1-{len(models)}) lub 'q' aby wyj≈õƒá: ").strip()
            
            if choice.lower() == 'q':
                print("Anulowano.")
                return None
            
            choice_idx = int(choice) - 1
            if 0 <= choice_idx < len(models):
                selected = models[choice_idx]
                print(f"\n‚úÖ Wybrano: {selected['name']}")
                return selected['path']
            else:
                print(f"‚ùå Nieprawid≈Çowy wyb√≥r. Podaj liczbƒô 1-{len(models)}")
        except ValueError:
            print("‚ùå Nieprawid≈Çowy format. Podaj liczbƒô lub 'q'")
        except KeyboardInterrupt:
            print("\n\nAnulowano.")
            return None

# Custom env podobny do train, ale z real browser
class RealAgarIoEnv:
    def __init__(self, driver, reader, game_area=None):
        self.driver = driver
        self.reader = reader
        self.frame_history = config['environment']['frame_history']
        self.screen_size = config['environment']['screen_size']  # [W, H] = [256, 192]
        # Historia: (T, C, H, W) = (4, 3, 192, 256)
        screen_w, screen_h = self.screen_size
        self.history = np.zeros((self.frame_history, 3, screen_h, screen_w))
        
        # Dynamiczny obszar gry (wykryty przez OCR)
        self.game_area = game_area  # (x1, y1, x2, y2) lub None
        self.debug_frame_saved = False  # Flag dla zapisu debug frame
    
    def get_obs(self, save_debug=False):
        """Pobierz screenshot i przetw√≥rz do formatu modelu"""
        screenshot = self.driver.get_screenshot_as_png()
        img = cv2.imdecode(np.frombuffer(screenshot, np.uint8), cv2.IMREAD_COLOR)
        h, w = img.shape[:2]
        
        # Crop obszaru gry (musi byƒá wykryty!)
        if not self.game_area:
            raise ValueError("Obszar gry nie zosta≈Ç wykryty! Nie mo≈ºna kontynuowaƒá.")
        
        x1, y1, x2, y2 = self.game_area
        crop = img[y1:y2, x1:x2]
        
        # Zapisz debug frame (tylko raz)
        if save_debug and not self.debug_frame_saved:
            debug_dir = os.path.join(agario_dir, 'datasets')
            os.makedirs(debug_dir, exist_ok=True)
            cv2.imwrite(os.path.join(debug_dir, 'test_crop_debug.png'), crop)
            print(f"   üíæ Zapisano debug crop: datasets/test_crop_debug.png")
            self.debug_frame_saved = True
        
        # Resize do rozmiaru treningowego
        # screen_size = [W, H] = [256, 192]
        # cv2.resize przyjmuje (width, height)
        screen_w, screen_h = self.screen_size
        crop_resized = cv2.resize(crop, (screen_w, screen_h))  # (W=256, H=192)
        
        # BGR -> RGB i normalizacja
        crop = cv2.cvtColor(crop_resized, cv2.COLOR_BGR2RGB) / 255.0
        
        # (H, W, 3) -> (3, H, W)
        crop = np.transpose(crop, (2, 0, 1))
        
        # Aktualizuj historiƒô
        self.history = np.roll(self.history, -1, axis=0)
        self.history[-1] = crop
        
        # Zwr√≥ƒá bez batch dimension - model.predict sam go doda
        # Format: (T=4, C=3, H=192, W=256)
        return self.history
    
    def act(self, action):
        """Wykonaj akcjƒô w grze"""
        # action shape: (1, 3) lub (3,)
        if action.ndim == 2:
            action = action[0]  # Usu≈Ñ batch dim
        
        dx = float(action[0])
        dy = float(action[1])
        split_eject = float(action[2])
        
        # Ruch myszy (symulacja - wymaga pyautogui)
        try:
            import pyautogui
            # Skala ruchu (dostosuj do szybko≈õci gry)
            scale = 50
            pyautogui.moveRel(int(dx * scale), int(dy * scale), duration=0.05)
            
            # Split / Eject
            if split_eject > 0.7:
                pyautogui.press('w')  # Split
            elif split_eject > 0.3:
                pyautogui.press('space')  # Eject
        except ImportError:
            print("‚ö†Ô∏è  pyautogui nie zainstalowane - ruch myszy wy≈ÇƒÖczony")
            print("   Zainstaluj: pip install pyautogui")

def setup_chrome_with_adblock():
    """Skonfiguruj Chrome z blokowaniem reklam"""
    chrome_options = Options()
    chrome_options.add_argument("--start-maximized")
    chrome_options.add_argument("--disable-blink-features=AutomationControlled")
    
    # Blokowanie reklam - wbudowane filtry Chrome
    chrome_options.add_experimental_option("prefs", {
        "profile.default_content_setting_values.notifications": 2,  # Blokuj powiadomienia
        "profile.managed_default_content_settings.images": 1,  # Pozw√≥l na obrazy
    })
    
    # Dodatkowo: Blokuj niekt√≥re domeny reklamowe
    chrome_options.add_argument("--disable-popup-blocking")
    
    # User agent (nie wyglƒÖda jak bot)
    chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
    
    return chrome_options

def detect_game_area(driver, reader, max_attempts=3):
    """
    Wykryj obszar planszy gry u≈ºywajƒÖc OCR (Score i Leaderboard).
    Zwraca: (x1, y1, x2, y2) lub None je≈õli nie wykryto
    """
    for attempt in range(max_attempts):
        print(f"   Pr√≥ba {attempt+1}/{max_attempts}...", end='\r')
        
        screenshot = driver.get_screenshot_as_png()
        img = cv2.imdecode(np.frombuffer(screenshot, np.uint8), cv2.IMREAD_COLOR)
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        
        # OCR z ni≈ºszym threshold
        result = reader.readtext(img_rgb, detail=1, paragraph=False)
        
        score_bbox = None
        leaderboard_bbox = None
        
        # Debug: poka≈º wszystkie wykryte teksty
        if attempt == 0:
            print(f"\n   [OCR] Wykryto {len(result)} tekst√≥w:")
            for bbox, text, conf in result[:10]:  # Poka≈º pierwsze 10
                print(f"      '{text}' (conf: {conf:.2f})")
        
        for bbox, text, conf in result:
            txt = text.lower()
            # Bardziej elastyczne dopasowanie
            if ('score' in txt or 'scor' in txt) and conf > 0.2:
                score_bbox = bbox
                if attempt == 0:
                    print(f"   ‚úÖ Znaleziono 'Score': '{text}' (conf: {conf:.2f})")
            if ('leaderboard' in txt or 'leader' in txt) and conf > 0.2:
                leaderboard_bbox = bbox
                if attempt == 0:
                    print(f"   ‚úÖ Znaleziono 'Leaderboard': '{text}' (conf: {conf:.2f})")
        
        if score_bbox and leaderboard_bbox:
            # Wyznacz obszar gry miƒôdzy Score (g√≥ra) a Leaderboard (prawo)
            x1 = int(min(p[0] for p in score_bbox))
            y2 = int(max(p[1] for p in score_bbox))
            x2 = int(max(p[0] for p in leaderboard_bbox))
            y1 = int(min(p[1] for p in leaderboard_bbox))
            
            # Walidacja
            x1 = max(x1, 0)
            y1 = max(y1, 0)
            x2 = min(x2, img.shape[1])
            y2 = min(y2, img.shape[0])
            
            # Sprawd≈∫ czy rozmiar jest sensowny
            width = x2 - x1
            height = y2 - y1
            if width > 100 and height > 100:  # Min 100x100 px
                print(f"\n   ‚úÖ Obszar: {width}x{height} px")
                
                # Zapisz debug screenshot z zaznaczonym obszarem
                debug_img = img.copy()
                # Zaznacz Score bbox (czerwony)
                score_pts = np.array(score_bbox, np.int32)
                cv2.polylines(debug_img, [score_pts], isClosed=True, color=(0,0,255), thickness=3)
                # Zaznacz Leaderboard bbox (zielony)
                leader_pts = np.array(leaderboard_bbox, np.int32)
                cv2.polylines(debug_img, [leader_pts], isClosed=True, color=(0,255,0), thickness=3)
                # Zaznacz wykryty obszar gry (niebieski prostokƒÖt)
                cv2.rectangle(debug_img, (x1, y1), (x2, y2), (255,0,0), 3)
                # Zapisz
                debug_dir = os.path.join(agario_dir, 'datasets')
                os.makedirs(debug_dir, exist_ok=True)
                cv2.imwrite(os.path.join(debug_dir, 'game_area_detection_debug.png'), debug_img)
                print(f"   üíæ Zapisano debug: datasets/game_area_detection_debug.png")
                
                return (x1, y1, x2, y2)
        
        time.sleep(0.5)  # Czekaj przed kolejnƒÖ pr√≥bƒÖ
    
    print("\n   ‚ö†Ô∏è  Nie uda≈Ço siƒô wykryƒá obu element√≥w")
    return None

def is_in_game(driver, reader):
    """
    Sprawd≈∫ czy jeste≈õmy w grze (vs menu).
    Zwraca: True je≈õli wykryto 'Score', False je≈õli w menu
    """
    try:
        # Sprawd≈∫ canvas
        canvas = driver.find_elements(By.ID, "canvas")
        if not canvas or not canvas[0].is_displayed():
            return False
        
        # Sprawd≈∫ Score przez OCR
        screenshot = driver.get_screenshot_as_png()
        img = cv2.imdecode(np.frombuffer(screenshot, np.uint8), cv2.IMREAD_COLOR)
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        
        result = reader.readtext(img_rgb, detail=0, paragraph=False)
        
        for text in result:
            if 'score' in text.lower():
                return True
        
        return False
    except:
        return False

def wait_for_game_start(driver, reader, max_wait=60):
    """
    Czeka a≈º u≈ºytkownik przejdzie przez menu i rozpocznie grƒô.
    U≈ºywa OCR do wykrycia 'Score' w grze.
    Zwraca: (success, game_area) - game_area to (x1,y1,x2,y2) lub None
    """
    print(f"\n‚è≥ Czekam na start gry (max {max_wait}s)...")
    print("   üëâ Kliknij 'Play' w przeglƒÖdarce gdy bƒôdziesz gotowy!")
    print("   üí° TIP: Zamknij reklamy je≈õli siƒô pojawiƒÖ")
    
    start_time = time.time()
    last_update = 0
    
    while time.time() - start_time < max_wait:
        try:
            # Sprawd≈∫ czy jeste≈õmy w grze (wykryj Score)
            if is_in_game(driver, reader):
                print("\n‚úÖ Gra wykryta (Score znaleziony) - poczekaj na stabilizacjƒô...")
                time.sleep(3)  # Poczekaj a≈º UI siƒô ustabilizuje
                
                # Teraz wykryj obszar gry (Score powinien byƒá ju≈º widoczny)
                print("üéØ Wykrywanie obszaru gry...")
                game_area = detect_game_area(driver, reader, max_attempts=5)
                
                if game_area:
                    x1, y1, x2, y2 = game_area
                    print(f"‚úÖ Wykryto obszar gry: ({x1}, {y1}) -> ({x2}, {y2})")
                    return True, game_area
                else:
                    print("‚ùå Nie uda≈Ço siƒô wykryƒá Score i Leaderboard!")
                    print("   Spr√≥buj ponownie - upewnij siƒô ≈ºe gra jest w pe≈Çni za≈Çadowana.")
                    return False, None
            
            # Progress bar co sekundƒô
            elapsed = int(time.time() - start_time)
            if elapsed > last_update:
                remaining = max_wait - elapsed
                print(f"   Oczekiwanie... ({elapsed}s / {max_wait}s, pozosta≈Ço: {remaining}s)", end='\r')
                last_update = elapsed
            
            time.sleep(0.5)
            
        except Exception as e:
            pass  # Ignoruj b≈Çƒôdy, po prostu czekaj
    
    print(f"\n‚ö†Ô∏è  Up≈ÇynƒÖ≈Ç limit czasu ({max_wait}s)")
    resp = input("Kontynuowaƒá mimo to? [Y/n]: ").strip()
    return (resp.lower() not in ('n', 'no'), None)

def test_model(model_path):
    """Testuj model na prawdziwym Agar.io"""
    print("\n" + "="*60)
    print("ROZPOCZYNANIE TESTU")
    print("="*60)
    
    # Wczytaj model
    print(f"\nüì¶ ≈Åadowanie modelu: {os.path.basename(model_path)}")
    try:
        model = PPO.load(model_path)
        model.policy.eval()
        print("‚úÖ Model za≈Çadowany")
    except Exception as e:
        print(f"‚ùå B≈ÇƒÖd ≈Çadowania modelu: {e}")
        return
    
    # Inicjalizuj OCR
    print("\nüîç Inicjalizacja OCR (EasyOCR)...")
    try:
        reader = easyocr.Reader(['en'], gpu=True)
        print("‚úÖ OCR gotowy (GPU)")
    except:
        reader = easyocr.Reader(['en'], gpu=False)
        print("‚úÖ OCR gotowy (CPU)")
    
    # Uruchom przeglƒÖdarkƒô z AdBlock
    print("\nüåê Uruchamianie Chrome z blokowaniem reklam...")
    try:
        chrome_options = setup_chrome_with_adblock()
        driver = webdriver.Chrome(options=chrome_options)
        driver.get("https://agar.io")
        print("‚úÖ PrzeglƒÖdarka uruchomiona")
        
        # Czekaj na start gry (wykrywa r√≥wnie≈º obszar gry)
        game_started, game_area = wait_for_game_start(driver, reader, max_wait=60)
        
        if not game_started:
            print("‚ùå Anulowano przez u≈ºytkownika")
            driver.quit()
            return
            
    except Exception as e:
        print(f"‚ùå B≈ÇƒÖd uruchamiania przeglƒÖdarki: {e}")
        print("   Upewnij siƒô ≈ºe masz zainstalowany ChromeDriver")
        return
    
    # Testowanie
    env = RealAgarIoEnv(driver, reader, game_area)
    
    print("\nüéÆ ROZPOCZYNAM TEST (Ctrl+C aby zatrzymaƒá)")
    print("="*60)
    
    start_time = time.time()
    step_count = 0
    last_score_check = time.time()
    
    try:
        while True:
            # Co 2 sekundy sprawd≈∫ czy Score jest widoczny
            if time.time() - last_score_check >= 2.0:
                if not is_in_game(driver, reader):
                    print("\n\n‚ö†Ô∏è  Gra zako≈Ñczona (brak Score przez 2s) - zatrzymujƒô test")
                    break
                last_score_check = time.time()
            
            # Pobierz obserwacjƒô (zapisz debug w pierwszej iteracji)
            obs = env.get_obs(save_debug=(step_count == 0))
            
            # Przewid≈∫ akcjƒô
            with torch.no_grad():
                action, _ = model.predict(obs, deterministic=True)
            
            # Debug pierwszej iteracji
            if step_count == 0:
                print(f"\n[DEBUG] action type: {type(action)}")
                print(f"[DEBUG] action shape: {action.shape if hasattr(action, 'shape') else 'N/A'}")
                print(f"[DEBUG] action value: {action}\n")
            
            # Wykonaj akcjƒô
            env.act(action)
            
            step_count += 1
            elapsed = time.time() - start_time
            
            # Status co 10 krok√≥w
            if step_count % 10 == 0:
                fps = step_count / elapsed
                # Bezpieczne wy≈õwietlanie akcji
                if hasattr(action, 'shape') and len(action.shape) > 0:
                    if action.shape[0] >= 3:
                        action_str = f"[{action[0]:+.2f}, {action[1]:+.2f}, {action[2]:.2f}]"
                    else:
                        action_str = str(action)
                else:
                    action_str = str(action)
                print(f"Krok: {step_count:4d} | Czas: {elapsed:6.1f}s | FPS: {fps:5.1f} | Akcja: {action_str}", end='\r')
            
    except KeyboardInterrupt:
        print(f"\n\n‚èπÔ∏è  Test zatrzymany przez u≈ºytkownika")
    except Exception as e:
        print(f"\n\n‚ùå B≈ÇƒÖd podczas testu: {e}")
    finally:
        elapsed = time.time() - start_time
        print("\n" + "="*60)
        print("PODSUMOWANIE")
        print("="*60)
        print(f"Czas testu: {elapsed:.1f}s ({elapsed/60:.1f} min)")
        print(f"Liczba krok√≥w: {step_count}")
        print(f"≈örednie FPS: {step_count/elapsed:.1f}")
        print("\nüîö Zamykam przeglƒÖdarkƒô...")
        driver.quit()
        print("‚úÖ Test zako≈Ñczony")

def main():
    """G≈Ç√≥wna funkcja"""
    model_path = select_model()
    
    if model_path:
        test_model(model_path)
    
    print("\nDziƒôkujƒô za u≈ºycie testera! üëã")

if __name__ == "__main__":
    main()