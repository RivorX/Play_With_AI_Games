# Konfiguracja ≈õrodowiska Snake
environment:
  min_grid_size: 5                   # Minimalny rozmiar siatki
  max_grid_size: 25                  # Maksymalny rozmiar siatki
  viewport_size: 16                  # Rozmiar viewport (sta≈Çy dla wszystkich grid_size)
  snake_size: 20                     # Rozmiar kratki w pikselach
  directions: [[0, -1], [1, 0], [0, 1], [-1, 0]]  # Kierunki ruchu wƒô≈ºa
  observation_space:
    low: -1.0                        # Minimalna warto≈õƒá obserwacji
    high: 1.0                        # Maksymalna warto≈õƒá obserwacji
    dtype: float32                   # Typ danych obserwacji
  action_space:
    type: Discrete                   # Typ przestrzeni akcji
    n: 3                             # Liczba akcji (lewo, prosto, prawo)
  max_steps_without_food: 20         # Max krok√≥w bez jedzenia (skalowane z rozmiarem)
  max_steps_factor: 200              # Mno≈ºnik max krok√≥w

# Konfiguracja modelu RecurrentPPO
model:
  policy: MultiInputLstmPolicy       # Policy dla RecurrentPPO
  learning_rate: 0.0002              # Szybko≈õƒá uczenia 
  min_learning_rate: 0.00001         # Minimalny learning rate
  n_steps: 512                       # Liczba krok√≥w na aktualizacjƒô
  n_epochs: 4                        # Liczba epok 
  gamma: 0.99                        # Wsp√≥≈Çczynnik dyskontowania
  gae_lambda: 0.95                   # Lambda dla GAE
  clip_range: 0.2                    # Zakres obcinania PPO
  ent_coef: 0.05                     # Wsp√≥≈Çczynnik entropii (poczƒÖtkowy)
  min_ent_coef: 0.03                 # Minimalny wsp√≥≈Çczynnik entropii (docelowy)
  vf_coef: 0.5                       # Wsp√≥≈Çczynnik funkcji warto≈õci
  device: cuda                       # UrzƒÖdzenie (cuda/cpu)
  
  # ‚úÖ NOWE: Konfiguracja optymalizatora
  optimizer:
    type: adamw                      # Typ: 'adam' lub 'adamw'
    weight_decay: 0.005              # Weight decay dla AdamW (0.0 = wy≈ÇƒÖczone)
    eps: 1.0e-7                      # Epsilon dla stabilno≈õci
    betas: [0.9, 0.999]              # Beta1, Beta2 dla Adam/AdamW

  # üÜï LSTM Configuration (Fix 2)
  lstm:
    gradient_clip_val: 1.0           # Clip gradients LSTM
    cell_state_penalty: 0.005        # L2 penalty na cell state
    hidden_state_penalty: 0.0005     # L2 penalty na hidden state
    dropout: 0.1                     # Dropout w LSTM
  
  # Selektywne dropouty
  cnn_dropout: 0.005                 # Dropout dla CNN
  scalar_dropout: 0.01               # Dropout dla skalar√≥w
  scalar_input_dropout: 0.0          # Dropout dla wej≈õcia skalar√≥w
  fusion_dropout: 0.05               # Dropout po fuzji
  
  # CNN ARCHITECTURE
  convlstm:
    cnn_channels: [32, 64]           # Kana≈Çy CNN (nie zmieniaj)
    
    # üÜï CNN Bottleneck Architecture (zoptymalizowane pod 4GB VRAM)
    cnn_bottleneck_dim: 640          # Mniejsze (by≈Ço 512)
    cnn_output_dim: 896              # Mniejsze (by≈Ço 1024)
    
    # üÜï Scalar Network Architecture  
    scalar_hidden_dims: [192, 128]    # Mniejsze
    
    # üÜï Architecture Options
    use_layernorm: true              # LayerNorm (OK dla VRAM)
    learnable_alpha: true            # Learnable alpha (OK dla VRAM)
    initial_alpha: 0.5               # PoczƒÖtkowa waga residual

  policy_kwargs:
    features_extractor_kwargs:
      features_dim: 768              # Wymiar cech wyj≈õciowych ekstraktora
    net_arch:
      pi: [320, 160]                 # Wielko≈õƒá sieci aktora
      vf: [320, 160]                 # Wielko≈õƒá sieci krytyka
    lstm_hidden_size: 320            # Rozmiar ukryty LSTM
    n_lstm_layers: 1                 # Liczba warstw LSTM
    enable_critic_lstm: false        # LSTM dla krytyka

# Konfiguracja treningu
training:
  n_envs: 12                         # Liczba ≈õrodowisk
  batch_size: 512                    # Rozmiar partii
  total_timesteps: 10000000          # Ca≈Çkowita liczba krok√≥w
  eval_freq: 4000                    # Czƒôstotliwo≈õƒá ewaluacji
  plot_interval: 1                   # Co ile walidacji robiƒá wykres i zapisywaƒá model
  max_no_improvement_evals: 30       # Liczba ewaluacji bez poprawy przed zatrzymaniem
  min_evals: 10                      # Minimalna liczba ewaluacji przed sprawdzeniem zatrzymania
  enable_channel_logs: false         # W≈ÇƒÖcz logi kana≈Ç√≥w
  gradient_log_freq: 2000            # ‚úÖ NOWE: Co ile krok√≥w logowaƒá gradienty/wagi
  # Liczba ≈õrodowisk do ewaluacji r√≥wnoleg≈Çej
  eval_n_envs: 6                     # Liczba ≈õrodowisk ewaluacyjnych
  eval_n_repeats: 2                  # Ile razy ka≈ºde ≈õrodowisko ma wykonaƒá ewaluacjƒô
  
  # Konfiguracja normalizacji (PRZE≈ÅƒÑCZNIKI)
  normalization:
    norm_obs: false                  # ‚ùå FALSE dla obraz√≥w (CNN radzi sobie z surowymi pikselami)
    norm_reward: true                # ‚úÖ TRUE - stabilizuje trening (running mean rewards)
    clip_obs: 10.0                   # Clipping obserwacji (tylko je≈õli norm_obs=true)
    clip_reward: 10.0                # Clipping nagr√≥d (10.0 = standardowa warto≈õƒá)
    gamma: 0.99                      # Gamma dla running mean rewards (powinno = model.gamma)
    
    # DODATKOWE OPCJE (zaawansowane)
    norm_obs_keys: []                # Lista kluczy do normalizacji (puste = wszystkie, je≈õli norm_obs=true)
                                     # Przyk≈Çad: ['dx_head', 'dy_head'] - tylko skalary
    epsilon: 1.0e-8                  # Epsilon dla stabilno≈õci numerycznej
    clip_obs_asymmetric: false       # Asymetryczne clipping: (-clip_obs, clip_obs) vs (0, clip_obs)

# ≈öcie≈ºki do zapisu
paths:
  models_dir: models
  logs_dir: logs
  model_path: models/snake_ppo_model.zip
  train_csv_path: logs/train_progress.csv
  plot_path: logs/training_progress.png
  test_progress_path: logs/test_progress.png