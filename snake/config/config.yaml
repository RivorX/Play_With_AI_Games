# Konfiguracja środowiska Snake
environment:
  min_grid_size: 5                   # Minimalny rozmiar siatki dla losowania
  max_grid_size: 25                  # Maksymalny rozmiar siatki (może być >16 dzięki viewport!)
  snake_size: 20                     # Rozmiar kratki w pikselach (dla renderowania)
  directions: [[0, -1], [1, 0], [0, 1], [-1, 0]]  # Kierunki ruchu węża [lewo, dół, prawo, góra]
  observation_space:
    low: -1.0                        # Minimalna wartość obserwacji (-1 = ściany)
    high: 1.0                        # Maksymalna wartość obserwacji
    dtype: float32                   # Typ danych obserwacji
  action_space:
    type: Discrete                    # Typ przestrzeni akcji
    n: 3                             # Liczba akcji (lewo, prosto, prawo)
  max_steps_without_food: 10         # Max kroków bez jedzenia (skalowane z rozmiarem)
  max_steps_factor: 150              # Mnożnik max kroków

# Konfiguracja modelu RecurrentPPO
model:
  policy: MultiInputLstmPolicy       # MultiInputLstmPolicy dla RecurrentPPO
  learning_rate: 0.0003              # Szybkość uczenia 
  min_learning_rate: 0.00003         # Minimalny learning rate (nie schodzi poniżej)
  schedule_type: cosine 
  n_steps: 2048                      # Liczba kroków na aktualizację (zmniejszone dla VRAM)
  n_epochs: 5                        # Liczba epok 
  gamma: 0.99                        # Współczynnik dyskontowania
  gae_lambda: 0.95                   # Lambda dla GAE
  clip_range: 0.2                    # Zakres obcinania PPO
  ent_coef: 0.02                     # Współczynnik entropii (zmniejszone z 0.05)
  vf_coef: 0.5                       # Współczynnik funkcji wartości (zmniejszone z 1.0)
  device: cuda                       # Urządzenie (cuda/cpu)
  dropout_rate: 0.1
  
  # Parametry CNN
  convlstm:
    cnn_channels: [24, 32, 40]      # Liczba kanałów w warstwach konwolucyjnych
    scalar_hidden_dims: [128]       # Ukryte wymiary dla danych skalarnych  
  
  policy_kwargs:
    features_extractor_kwargs:
      features_dim: 256              
    net_arch:
      pi: [128, 64]                    
      vf: [128, 64]                    
    lstm_hidden_size: 128            
    n_lstm_layers: 1                  # Liczba warstw LSTM
    enable_critic_lstm: true          # LSTM także dla krytyka

# Konfiguracja treningu
training:
  n_envs: 8                          # Zwiększone z powrotem do 8
  batch_size: 2048                   # Rozmiar partii
  total_timesteps: 10000000          # Całkowita liczba kroków
  eval_freq: 5000                    # Częstotliwość ewaluacji (rzadziej)
  plot_interval: 1                   # Co ile walidacji robić wykres
  max_no_improvement_evals: 20       # Liczba ewaluacji bez poprawy przed zatrzymaniem
  min_evals: 5                       # Minimalna liczba ewaluacji
  enable_channel_logs: false         # Wyłącz logi kanałów (wydajność)

# Ścieżki do zapisu
paths:
  models_dir: models
  logs_dir: logs
  model_path: models/snake_ppo_model.zip
  train_csv_path: logs/train_progress.csv
  plot_path: logs/training_progress.png
  test_progress_path: logs/test_progress.png