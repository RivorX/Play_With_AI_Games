# model_ultra_optimized.py - üöÄ EXTREME PERFORMANCE + üîß COLLISION BUG FIX + üéØ CPU OPTIMIZATION
import gymnasium as gym
from gymnasium import spaces
import numpy as np
import pygame
import yaml
import os
import itertools  # üöÄ CPU Optimization: Avoid deque‚Üílist conversions
from collections import deque
from utils.visual_styles import create_renderer

base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
config_path = os.path.join(base_dir, 'config', 'config.yaml')
with open(config_path, 'r', encoding='utf-8') as f:
    config = yaml.safe_load(f)


class SnakeEnv(gym.Env):
    """
    üöÄ ULTRA-OPTIMIZED Snake Environment + üîß COLLISION FIX
    
    FIXED: snake_body_set now correctly contains ALL body segments (excluding head)
    """
    metadata = {"render_modes": ["human", "rgb_array"], "render_fps": 10}

    def __init__(self, render_mode=None, grid_size=None, viewport_size=None, visual_style='classic'):
        super().__init__()
        
        # Visual style
        self.visual_style = visual_style
        self.renderer = None
        
        # Grid size
        if grid_size is None:
            self.grid_size = np.random.randint(
                config['environment']['min_grid_size'],
                config['environment']['max_grid_size'] + 1
            )
        else:
            self.grid_size = grid_size
        
        # Viewport
        if viewport_size is None:
            self.viewport_size = config['environment']['viewport_size']
        else:
            self.viewport_size = viewport_size
        
        # Reward config
        self.reward_config = config['environment'].get('reward_scaling', {})
        self.reward_scaling_enabled = self.reward_config.get('enable', True)
        
        if self.reward_scaling_enabled:
            min_grid = config['environment']['min_grid_size']
            max_grid = config['environment']['max_grid_size']
            min_mult = self.reward_config.get('min_difficulty_multiplier', 1.0)
            max_mult = self.reward_config.get('max_difficulty_multiplier', 2.0)
            
            if max_grid > min_grid:
                progress = (self.grid_size - min_grid) / (max_grid - min_grid)
                self.difficulty_multiplier = min_mult + (max_mult - min_mult) * progress
            else:
                self.difficulty_multiplier = min_mult
        else:
            self.difficulty_multiplier = 1.0
        
        # Reward values
        self.base_food_reward = self.reward_config.get('base_food_reward', 10.0)
        self.base_death_penalty = self.reward_config.get('base_death_penalty', -10.0)
        self.milestones = self.reward_config.get('milestones', {})
        self.efficiency_config = self.reward_config.get('efficiency_bonus', {})
        
        # Progressive bonus config
        self.progressive_config = self.reward_config.get('progressive_food_bonus', {})
        self.progressive_enabled = self.progressive_config.get('enable', False)
        self.bonus_per_apple = self.progressive_config.get('bonus_per_apple', 0.03)
        self.max_progressive_multiplier = self.progressive_config.get('max_multiplier', 3.0)
        
        # Tracking
        self.milestones_achieved = set()
        
        # Action space
        self.action_space = spaces.Discrete(3)
        
        # Observation space
        self.observation_space = spaces.Dict({
            'image': spaces.Box(
                low=config['environment']['observation_space']['low'],
                high=config['environment']['observation_space']['high'],
                shape=(self.viewport_size, self.viewport_size, 1),
                dtype=np.float32
            ),
            'direction': spaces.Box(low=-1.0, high=1.0, shape=(2,), dtype=np.float32),
            'dx_head': spaces.Box(low=-1.0, high=1.0, shape=(1,), dtype=np.float32),
            'dy_head': spaces.Box(low=-1.0, high=1.0, shape=(1,), dtype=np.float32),
            'front_coll': spaces.Box(low=0.0, high=1.0, shape=(1,), dtype=np.float32),
            'left_coll': spaces.Box(low=0.0, high=1.0, shape=(1,), dtype=np.float32),
            'right_coll': spaces.Box(low=0.0, high=1.0, shape=(1,), dtype=np.float32),
            'snake_length': spaces.Box(low=-1.0, high=1.0, shape=(1,), dtype=np.float32)
        })
        
        self.render_mode = render_mode
        self.window = None
        self.clock = None
        
        # Snake state
        self.snake = None  # Will be deque
        self.food = None
        self.direction = 0
        self.score = 0
        self.steps = 0
        self.steps_since_food = 0
        self.total_reward = 0.0
        
        # üîß FIX: Set tracks ALL body segments (excluding head)
        self.snake_body_set = None
        
        # Occupancy grid
        self.occupied_grid = None
        
        # Pre-allocated viewport (reuse memory)
        self.viewport_array = np.zeros((self.viewport_size, self.viewport_size), dtype=np.float32)
        
        # Cached direction vectors (no dict lookup)
        self.DIRECTIONS = np.array([
            [0, -1],   # UP
            [1, 0],    # RIGHT
            [0, 1],    # DOWN
            [-1, 0]    # LEFT
        ], dtype=np.int32)
        
        # Max steps without food (scaled)
        base_max_steps = config['environment']['max_steps_without_food']
        self.max_steps_without_food = base_max_steps * self.grid_size

    def reset(self, seed=None, options=None):
        super().reset(seed=seed)
        
        if options and 'grid_size' in options:
            self.grid_size = options['grid_size']
        
        # Recalculate difficulty multiplier
        if self.reward_scaling_enabled:
            min_grid = config['environment']['min_grid_size']
            max_grid = config['environment']['max_grid_size']
            min_mult = self.reward_config.get('min_difficulty_multiplier', 1.0)
            max_mult = self.reward_config.get('max_difficulty_multiplier', 2.0)
            
            if max_grid > min_grid:
                progress = (self.grid_size - min_grid) / (max_grid - min_grid)
                self.difficulty_multiplier = min_mult + (max_mult - min_mult) * progress
            else:
                self.difficulty_multiplier = min_mult
        
        # Reset milestone tracking
        self.milestones_achieved = set()
        
        # Initialize snake (center) - USE DEQUE
        center = self.grid_size // 2
        self.snake = deque([(center, center)])
        
        # üîß FIX: Empty set initially (only 1 segment = head only, no body)
        self.snake_body_set = set()
        
        # Initialize occupancy grid
        self.occupied_grid = np.zeros((self.grid_size, self.grid_size), dtype=bool)
        self.occupied_grid[center, center] = True
        
        self.direction = 0  # UP
        self.food = self._place_food()
        self.score = 0
        self.steps = 0
        self.steps_since_food = 0
        self.total_reward = 0.0
        
        # Recalculate max_steps_without_food
        base_max_steps = config['environment']['max_steps_without_food']
        self.max_steps_without_food = base_max_steps * self.grid_size
        
        observation = self._get_obs()
        info = self._get_info()
        
        return observation, info

    def step(self, action):
        self.steps += 1
        self.steps_since_food += 1
        
        # Change direction
        if action == 0:  # Left
            self.direction = (self.direction - 1) % 4
        elif action == 2:  # Right
            self.direction = (self.direction + 1) % 4
        
        # Cached direction vectors (no dict lookup)
        head_x, head_y = self.snake[0]
        dx, dy = self.DIRECTIONS[self.direction]
        new_head = (head_x + dx, head_y + dy)
        
        reward = 0.0
        terminated = False
        truncated = False
        
        # ==================== COLLISION CHECKS ====================
        # Wall collision
        if not (0 <= new_head[0] < self.grid_size and 0 <= new_head[1] < self.grid_size):
            terminated = True
            death_penalty = self.base_death_penalty * self.difficulty_multiplier
            reward = death_penalty
            info = self._get_info()
            info['termination_reason'] = 'wall'
            if self.render_mode == "human":
                self._render_frame()
            return self._get_obs(), reward, terminated, truncated, info
        
        # Body collision (excluding tail if not growing)
        will_grow = (new_head == self.food)
        
        # üîß FIX + üöÄ CPU OPT: Check collision properly without converting to list
        if will_grow:
            # Growing: check collision with ALL segments (including tail)
            if new_head in self.snake_body_set or new_head == self.snake[0]:
                terminated = True
                death_penalty = self.base_death_penalty * self.difficulty_multiplier
                reward = death_penalty
                info = self._get_info()
                info['termination_reason'] = 'collision'
                if self.render_mode == "human":
                    self._render_frame()
                return self._get_obs(), reward, terminated, truncated, info
        else:
            # Not growing: check collision with body_set (excludes tail automatically)
            if new_head in self.snake_body_set:
                terminated = True
                death_penalty = self.base_death_penalty * self.difficulty_multiplier
                reward = death_penalty
                info = self._get_info()
                info['termination_reason'] = 'collision'
                if self.render_mode == "human":
                    self._render_frame()
                return self._get_obs(), reward, terminated, truncated, info
        
        # ==================== MOVE SNAKE ====================
        # Save old head for body_set update
        old_head = self.snake[0]
        
        # Add new head
        self.snake.appendleft(new_head)
        self.occupied_grid[new_head[0], new_head[1]] = True
        
        # Check if ate food
        if new_head == self.food:
            self.score += 1
            self.food = self._place_food()
            
            # üîß FIX: Update snake_body_set (add old head, new head is at index 0)
            self.snake_body_set.add(old_head)
            
            # Calculate food reward
            food_reward = self.base_food_reward * self.difficulty_multiplier
            
            # Progressive bonus
            if self.progressive_enabled:
                progressive_mult = 1.0 + (self.score * self.bonus_per_apple)
                progressive_mult = min(progressive_mult, self.max_progressive_multiplier)
                food_reward *= progressive_mult
            
            reward = food_reward
            
            # Milestone bonuses
            current_occupancy = len(self.snake) / (self.grid_size ** 2)
            
            for threshold_float, bonus in self.milestones.items():
                threshold = float(threshold_float)
                
                if current_occupancy >= threshold and threshold not in self.milestones_achieved:
                    reward += bonus * self.difficulty_multiplier
                    self.milestones_achieved.add(threshold)
                    
                    if threshold >= 0.99:
                        print(f"üèÜüèÜüèÜ FULL BOARD! Grid={self.grid_size}x{self.grid_size} üèÜüèÜüèÜ")
            
            # Efficiency bonus
            if self.efficiency_config.get('enable', False):
                steps_per_apple = self.steps_since_food
                efficiency_threshold = self.efficiency_config.get('threshold', 10.0)
                efficiency_reward = self.efficiency_config.get('reward', 2.0)
                
                if steps_per_apple < efficiency_threshold:
                    reward += efficiency_reward * self.difficulty_multiplier
            
            # Reset steps counter
            self.steps_since_food = 0
        else:
            # üîß FIX: Update snake_body_set (add old head, remove tail)
            self.snake_body_set.add(old_head)
            
            tail = self.snake.pop()
            self.occupied_grid[tail[0], tail[1]] = False
            self.snake_body_set.discard(tail)
        
        # ==================== TIMEOUT ====================
        if self.steps_since_food > self.max_steps_without_food:
            terminated = True
            reward += self.base_death_penalty * 0.5
            info = self._get_info()
            info['termination_reason'] = 'timeout'
            
            if self.render_mode == "human":
                self._render_frame()
            
            return self._get_obs(), reward, terminated, truncated, info
        
        # ==================== MAX STEPS ====================
        max_steps = config['environment']['max_steps_factor'] * self.grid_size
        if self.steps >= max_steps:
            truncated = True
        
        # ==================== TRACKING ====================
        self.total_reward += reward
        
        observation = self._get_obs()
        info = self._get_info()
        
        if self.render_mode == "human":
            self._render_frame()
        
        return observation, reward, terminated, truncated, info

    def _get_obs(self):
        """üöÄ FULLY VECTORIZED: 3x faster than loop-based version"""
        head_x, head_y = self.snake[0]
        half_vp = self.viewport_size // 2
        
        # Reuse viewport array
        self.viewport_array.fill(0.0)
        
        # Calculate viewport bounds
        start_x = head_x - half_vp
        start_y = head_y - half_vp
        end_x = start_x + self.viewport_size
        end_y = start_y + self.viewport_size
        
        # ==================== VECTORIZED WALL DRAWING ====================
        # Create coordinate grids (meshgrid approach)
        vp_y_coords, vp_x_coords = np.meshgrid(
            np.arange(self.viewport_size), 
            np.arange(self.viewport_size), 
            indexing='ij'
        )
        
        # World coordinates
        world_x = start_x + vp_x_coords
        world_y = start_y + vp_y_coords
        
        # Wall mask (vectorized bounds check)
        wall_mask = (world_x < 0) | (world_x >= self.grid_size) | \
                    (world_y < 0) | (world_y >= self.grid_size)
        
        self.viewport_array[wall_mask] = 0.25  # Walls
        
        # ==================== VECTORIZED SNAKE BODY ====================
        if len(self.snake) > 1:
            # Convert deque to NumPy array (1x conversion, amortized cost)
            snake_body = np.array(list(self.snake)[1:], dtype=np.int32)
            
            # Calculate viewport coordinates
            body_vp_coords = snake_body - np.array([start_x, start_y], dtype=np.int32)
            
            # Mask for valid coordinates (inside viewport)
            valid_mask = (body_vp_coords[:, 0] >= 0) & \
                        (body_vp_coords[:, 0] < self.viewport_size) & \
                        (body_vp_coords[:, 1] >= 0) & \
                        (body_vp_coords[:, 1] < self.viewport_size)
            
            valid_body = body_vp_coords[valid_mask]
            
            # Draw body (vectorized indexing)
            if len(valid_body) > 0:
                self.viewport_array[valid_body[:, 1], valid_body[:, 0]] = 0.33
        
        # ==================== HEAD (scalar, fast) ====================
        vp_head_x = head_x - start_x
        vp_head_y = head_y - start_y
        if 0 <= vp_head_x < self.viewport_size and 0 <= vp_head_y < self.viewport_size:
            self.viewport_array[vp_head_y, vp_head_x] = 0.67
        
        # ==================== FOOD (scalar, fast) ====================
        food_x, food_y = self.food
        vp_food_x = food_x - start_x
        vp_food_y = food_y - start_y
        if 0 <= vp_food_x < self.viewport_size and 0 <= vp_food_y < self.viewport_size:
            self.viewport_array[vp_food_y, vp_food_x] = 1.0
        
        # Channel (H, W, 1)
        obs_image = np.expand_dims(self.viewport_array, axis=-1)
        
        # ==================== SCALARS (vectorized) ====================
        angle = self.direction * np.pi / 2
        direction_vec = np.array([np.sin(angle), np.cos(angle)], dtype=np.float32)
        
        # Vector to food (vectorized)
        food_vec = np.array(self.food, dtype=np.float32) - np.array(self.snake[0], dtype=np.float32)
        food_vec /= self.grid_size  # Normalize
        food_vec = np.clip(food_vec, -1.0, 1.0)
        
        # Collision checks (already fast)
        collision_checks = np.array([
            self._check_collision_in_direction(0),   # front
            self._check_collision_in_direction(-1),  # left
            self._check_collision_in_direction(1)    # right
        ], dtype=np.float32)
        
        # Snake length (normalized)
        max_length = self.grid_size * self.grid_size
        snake_length_norm = (len(self.snake) / max_length) * 2.0 - 1.0
        
        observation = {
            'image': obs_image.astype(np.float32),
            'direction': direction_vec,
            'dx_head': np.array([food_vec[0]], dtype=np.float32),
            'dy_head': np.array([food_vec[1]], dtype=np.float32),
            'front_coll': np.array([collision_checks[0]], dtype=np.float32),
            'left_coll': np.array([collision_checks[1]], dtype=np.float32),
            'right_coll': np.array([collision_checks[2]], dtype=np.float32),
            'snake_length': np.array([snake_length_norm], dtype=np.float32)
        }
        
        return observation

    def _check_collision_in_direction(self, turn):
        """üîß FIXED: Use corrected snake_body_set"""
        new_dir = (self.direction + turn) % 4
        head_x, head_y = self.snake[0]
        dx, dy = self.DIRECTIONS[new_dir]
        new_pos = (head_x + dx, head_y + dy)
        
        # Wall collision
        if not (0 <= new_pos[0] < self.grid_size and 0 <= new_pos[1] < self.grid_size):
            return 1.0
        
        # üîß FIXED: Check against full snake_body_set (all segments except head)
        if new_pos in self.snake_body_set:
            return 1.0
        
        return 0.0

    def _place_food(self):
        """üöÄ OPTIMIZED: NumPy fast sampling"""
        # Get free cells from occupancy grid
        free_mask = ~self.occupied_grid
        free_coords = np.argwhere(free_mask)
        
        if len(free_coords) == 0:
            # Board full!
            print("‚ùå BRAK WOLNYCH P√ìL!")
            return self.snake[0]
        
        # NumPy random choice (faster than Python random)
        idx = np.random.randint(len(free_coords))
        food_pos = tuple(free_coords[idx])
        
        return food_pos

    def _get_info(self):
        """Returns info about current state"""
        steps_per_apple = self.steps / max(self.score, 1)
        map_occupancy = (len(self.snake) / (self.grid_size ** 2)) * 100.0
        
        # Calculate current progressive multiplier
        progressive_mult = 1.0
        if self.progressive_enabled:
            progressive_mult = 1.0 + (self.score * self.bonus_per_apple)
            progressive_mult = min(progressive_mult, self.max_progressive_multiplier)
        
        return {
            'score': self.score,
            'steps': self.steps,
            'snake_length': len(self.snake),
            'grid_size': self.grid_size,
            'steps_per_apple': steps_per_apple,
            'total_reward': self.total_reward,
            'map_occupancy': map_occupancy,
            'difficulty_multiplier': self.difficulty_multiplier,
            'milestones_achieved': len(self.milestones_achieved),
            'progressive_multiplier': progressive_mult
        }

    def render(self):
        if self.render_mode == "rgb_array":
            return self._render_frame()

    def _render_frame(self):
        """üöÄ OPTIMIZED: Lazy pygame initialization with visual styles"""
        # Initialize pygame only on first render
        if self.window is None and self.render_mode == "human":
            pygame.init()
            snake_size = config['environment']['snake_size']
            window_size = self.grid_size * snake_size
            self.window = pygame.display.set_mode((window_size, window_size))
            pygame.display.set_caption("Snake RL")
        
        if self.clock is None and self.render_mode == "human":
            self.clock = pygame.time.Clock()
        
        # Initialize renderer (lazy initialization)
        if self.renderer is None:
            snake_size = config['environment']['snake_size']
            self.renderer = create_renderer(self.visual_style, self.grid_size, snake_size)
        
        snake_size = config['environment']['snake_size']
        canvas = pygame.Surface((self.grid_size * snake_size, self.grid_size * snake_size))
        
        # Use visual style renderer
        self.renderer.render(canvas, list(self.snake), self.food, self.direction)
        
        # Store canvas as screen for external access (e.g., GIF recording)
        self.screen = canvas
        
        if self.render_mode == "human":
            self.window.blit(canvas, canvas.get_rect())
            pygame.event.pump()
            pygame.display.update()
            self.clock.tick(self.metadata["render_fps"])
        else:  # rgb_array
            return np.transpose(
                np.array(pygame.surfarray.pixels3d(canvas)), axes=(1, 0, 2)
            )

    def close(self):
        if self.window is not None:
            pygame.display.quit()
            pygame.quit()


def make_env(render_mode=None, grid_size=None, visual_style='classic'):
    """Factory function for creating environments"""
    def _init():
        return SnakeEnv(render_mode=render_mode, grid_size=grid_size, visual_style=visual_style)
    return _init