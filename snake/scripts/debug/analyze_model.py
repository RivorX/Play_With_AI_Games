import os
import sys
import yaml
import torch
import numpy as np
import shutil
from sb3_contrib import RecurrentPPO

# Dodaj scripts do path
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
from model import make_env

# Import z utils/
from utils.analyze_activations import (
    analyze_basic_states,
    analyze_bottlenecks,
    plot_activation_overview,
    analyze_channel_specialization
)
from utils.analyze_lstm import (
    analyze_lstm_memory,
    analyze_confusion_matrix,
    analyze_uncertainty
)
from utils.analyze_advanced import (
    analyze_temporal_patterns,
    analyze_critical_moments,
    analyze_feature_importance
)

# Wczytaj konfiguracjÄ™
base_dir = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
config_path = os.path.join(base_dir, 'config', 'config.yaml')
with open(config_path, 'r', encoding='utf-8') as f:
    config = yaml.safe_load(f)

# ÅšcieÅ¼ka do najlepszego modelu
model_path = os.path.join(base_dir, config['paths']['models_dir'], 'best_model.zip')

# UtwÃ³rz katalogi na wyniki
output_dir = os.path.join(base_dir, 'logs', 'Analyze_model')

# âš ï¸ WAÅ»NE: WyczyÅ›Ä‡ poprzednie wyniki przed rozpoczÄ™ciem
if os.path.exists(output_dir):
    print(f"ğŸ—‘ï¸  Czyszczenie poprzednich wynikÃ³w z: {output_dir}")
    shutil.rmtree(output_dir)
    print("   âœ“ Katalog wyczyszczony")

# UtwÃ³rz strukturÄ™ katalogÃ³w
conv_viz_dir = os.path.join(output_dir, 'conv_visualizations')
viewport_dir = os.path.join(output_dir, 'viewports')
action_probs_dir = os.path.join(output_dir, 'action_probs')
heatmap_dir = os.path.join(output_dir, 'attention_heatmaps')
lstm_dir = os.path.join(output_dir, 'lstm_analysis')
uncertainty_dir = os.path.join(output_dir, 'uncertainty_analysis')
confusion_dir = os.path.join(output_dir, 'confusion_matrix')
temporal_dir = os.path.join(output_dir, 'temporal_patterns')
critical_dir = os.path.join(output_dir, 'critical_moments')
feature_dir = os.path.join(output_dir, 'feature_importance')

for dir_path in [output_dir, conv_viz_dir, viewport_dir, action_probs_dir, 
                 heatmap_dir, lstm_dir, uncertainty_dir, confusion_dir,
                 temporal_dir, critical_dir, feature_dir]:
    os.makedirs(dir_path, exist_ok=True)

# ZaÅ‚aduj model RecurrentPPO
print("="*80)
print("ğŸš€ MODEL ANALYSIS")
print("="*80)
print("\nÅadowanie modelu...")
model = RecurrentPPO.load(model_path)
policy = model.policy
features_extractor = policy.features_extractor

print(f"\n=== Informacje o modelu ===")
print(f"CNN channels: {config['model']['convlstm']['cnn_channels']}")
print(f"Bottleneck dims: {config['model']['convlstm'].get('cnn_bottleneck_dims', 'N/A')}")
print(f"CNN output dim: {config['model']['convlstm'].get('cnn_output_dim', 'N/A')}")
print(f"Scalar hidden dims: {config['model']['convlstm']['scalar_hidden_dims']}")
print(f"Features dim: {config['model']['policy_kwargs']['features_extractor_kwargs']['features_dim']}")
print(f"LSTM hidden size: {config['model']['policy_kwargs']['lstm_hidden_size']}")
print(f"LSTM layers: {config['model']['policy_kwargs']['n_lstm_layers']}")
print(f"Actor network: {config['model']['policy_kwargs']['net_arch']['pi']}")
print(f"Critic network: {config['model']['policy_kwargs']['net_arch']['vf']}")

# Przygotuj Å›rodowisko
env = make_env(render_mode=None, grid_size=16)()

# Nazwy akcji
action_names = ['lewo', 'prosto', 'prawo']

print("\n" + "="*80)
print("=== ROZPOCZÄ˜CIE ROZSZERZONEJ ANALIZY ===")
print("="*80)

# ===================================================
# CZÄ˜ÅšÄ† 1: ANALIZA PODSTAWOWA
# ===================================================
print("\n[1/10] Analiza podstawowych stanÃ³w, aktywacji i attention...")
action_probs_list, detailed_activations, layer_gradients, attention_heatmaps = analyze_basic_states(
    model=model,
    env=env,
    output_dirs={
        'conv_viz': conv_viz_dir,
        'viewport': viewport_dir,
        'action_probs': action_probs_dir,
        'heatmap': heatmap_dir
    },
    action_names=action_names,
    config=config
)

# ===================================================
# CZÄ˜ÅšÄ† 2: ANALIZA BOTTLENECKÃ“W
# ===================================================
print("\n[2/10] Analiza bottleneckÃ³w...")
bottleneck_report = analyze_bottlenecks(
    layer_gradients=layer_gradients,
    action_names=action_names,
    output_dir=output_dir
)

# ===================================================
# CZÄ˜ÅšÄ† 3: PRZEGLÄ„D AKTYWACJI
# ===================================================
print("\n[3/10] Generowanie wykresÃ³w przeglÄ…du aktywacji...")
plot_activation_overview(
    detailed_activations=detailed_activations,
    action_probs_list=action_probs_list,
    action_names=action_names,
    output_dirs={
        'main': output_dir,
        'action_probs': action_probs_dir
    }
)

# ===================================================
# CZÄ˜ÅšÄ† 4: ANALIZA LSTM MEMORY
# ===================================================
print("\n[4/10] Analiza LSTM memory...")
analyze_lstm_memory(
    model=model,
    env=env,
    output_dir=lstm_dir,
    action_names=action_names,
    config=config
)

# ===================================================
# CZÄ˜ÅšÄ† 5: CONFUSION MATRIX
# ===================================================
print("\n[5/10] Analiza Confusion Matrix...")
analyze_confusion_matrix(
    model=model,
    env=env,
    output_dir=confusion_dir,
    action_names=action_names,
    num_episodes=20
)

# ===================================================
# CZÄ˜ÅšÄ† 6: UNCERTAINTY ANALYSIS
# ===================================================
print("\n[6/10] Analiza Uncertainty...")
analyze_uncertainty(
    model=model,
    env=env,
    output_dir=uncertainty_dir,
    action_names=action_names,
    num_episodes=10
)

# ===================================================
# CZÄ˜ÅšÄ† 7: ANALIZA SPECJALIZACJI KANAÅÃ“W
# ===================================================
print("\n[7/10] Analiza specjalizacji kanaÅ‚Ã³w CNN...")
analyze_channel_specialization(
    model=model,
    env=env,
    output_dir=conv_viz_dir,
    num_samples=50
)

# ===================================================
# CZÄ˜ÅšÄ† 8: TEMPORAL PATTERNS ANALYSIS
# ===================================================
print("\n[8/10] Analiza wzorcÃ³w temporalnych (LSTM memory patterns)...")
analyze_temporal_patterns(
    model=model,
    env=env,
    output_dir=temporal_dir,
    action_names=action_names,
    num_episodes=20
)

# ===================================================
# CZÄ˜ÅšÄ† 9: CRITICAL MOMENTS ANALYSIS
# ===================================================
print("\n[9/10] Analiza krytycznych momentÃ³w (near-death, food acquisition)...")
analyze_critical_moments(
    model=model,
    env=env,
    output_dir=critical_dir,
    action_names=action_names,
    num_episodes=30
)

# ===================================================
# CZÄ˜ÅšÄ† 10: FEATURE IMPORTANCE ANALYSIS
# ===================================================
print("\n[10/10] Analiza waÅ¼noÅ›ci cech (ablation study)...")
analyze_feature_importance(
    model=model,
    env=env,
    output_dir=feature_dir,
    action_names=action_names,
    num_samples=100
)

env.close()

# ===================================================
# PODSUMOWANIE KOÅƒCOWE
# ===================================================
print("\n" + "="*80)
print("=== ANALIZA ZAKOÅƒCZONA ===")
print("="*80)
print(f"\nğŸ“‚ WaÅ¼ne pliki analizy:")
print(f"   {output_dir}/")
print(f"   â”œâ”€â”€ bottleneck_analysis.png                âš ï¸ Analiza bottleneckÃ³w")
print(f"   â”œâ”€â”€ bottleneck_report.csv                  ğŸ“Š Raport bottleneckÃ³w")
print(f"   â”œâ”€â”€ neuron_activations_overview.png        ğŸ§  PrzeglÄ…d aktywacji")
print(f"   â”œâ”€â”€ attention_heatmaps/                    ğŸ”¥ Attention heatmaps")
print(f"   â”œâ”€â”€ lstm_analysis/                         ğŸ§  Analiza LSTM memory")
print(f"   â”œâ”€â”€ confusion_matrix/                      ğŸ“Š Confusion matrix")
print(f"   â”œâ”€â”€ uncertainty_analysis/                  ğŸ² Uncertainty metrics")
print(f"   â”œâ”€â”€ temporal_patterns/                     ğŸ• Wzorce temporalne")
print(f"   â”œâ”€â”€ critical_moments/                      âš ï¸ Krytyczne momenty")
print(f"   â””â”€â”€ feature_importance/                    ğŸ¯ WaÅ¼noÅ›Ä‡ cech")

print("\n" + "="*80)
print("=== KLUCZOWE WYNIKI ===")
print("="*80)

print("\nğŸ”¥ ATTENTION HEATMAPS:")
print("   - PokazujÄ… ktÃ³re regiony viewport sÄ… najwaÅ¼niejsze dla decyzji")
print("   - Czerwone obszary = wysoka uwaga modelu")
print("   - SprawdÅº czy model patrzy na jedzenie, Å›ciany, czy wÅ‚asne ciaÅ‚o")

print("\nğŸ§  LSTM MEMORY ANALYSIS:")
print("   - lstm_memory_evolution.png: jak zmienia siÄ™ pamiÄ™Ä‡ w czasie")
print("   - lstm_neurons_heatmap.png: aktywacja wszystkich neuronÃ³w LSTM")
print("   - SprawdÅº czy LSTM faktycznie wykorzystuje pamiÄ™Ä‡ dÅ‚ugoterminowÄ…")

print("\nğŸ• TEMPORAL PATTERNS:")
print("   - temporal_ngrams.png: najczÄ™stsze sekwencje akcji (bigrams/trigrams)")
print("   - temporal_forgetting_curve.png: jak szybko LSTM zapomina")
print("   - temporal_entropy_evolution.png: niepewnoÅ›Ä‡ decyzji w czasie")

print("\nâš ï¸ CRITICAL MOMENTS:")
print("   - critical_near_death.png: zachowanie modelu przed kolizjÄ…")
print("   - critical_food_acquisition.png: efektywnoÅ›Ä‡ zbierania jedzenia")
print("   - critical_tight_spaces.png: decyzje w ciasnych przestrzeniach")

print("\nğŸ¯ FEATURE IMPORTANCE:")
print("   - feature_ablation_study.png: wpÅ‚yw CNN vs scalars")
print("   - feature_gradient_importance.png: gradient-based importance")
print("   - feature_importance_results.csv: szczegÃ³Å‚owe wyniki")

print("\nâš ï¸ BOTTLENECKS:")
if bottleneck_report:
    high_severity = [b for b in bottleneck_report if b['severity'] == 'HIGH']
    medium_severity = [b for b in bottleneck_report if b['severity'] == 'MEDIUM']
    if high_severity:
        print(f"   - ğŸ”´ WYSOKIE RYZYKO: {len(high_severity)} przypadkÃ³w")
    if medium_severity:
        print(f"   - ğŸŸ¡ ÅšREDNIE RYZYKO: {len(medium_severity)} przypadkÃ³w")
    if not high_severity and not medium_severity:
        print("   - âœ… Brak krytycznych bottleneckÃ³w")

print("\n" + "="*80)
print("âœ… ANALIZA ZAKOÅƒCZONA!")
print("="*80)