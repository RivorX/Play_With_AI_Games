import os
import sys
import yaml
import torch
import numpy as np
from sb3_contrib import RecurrentPPO

# Dodaj scripts do path
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
from model import make_env

# Import WSZYSTKICH modu≈Ç√≥w analizy
from analyze_activations import (
    analyze_basic_states,
    analyze_bottlenecks,
    plot_activation_overview,
    analyze_channel_specialization
)
from analyze_lstm import (
    analyze_lstm_memory,
    analyze_confusion_matrix,
    analyze_uncertainty
)
from analyze_advanced import (
    analyze_temporal_patterns,
    analyze_critical_moments,
    analyze_feature_importance,
    analyze_bottleneck_architecture
)

# Wczytaj konfiguracjƒô
base_dir = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
config_path = os.path.join(base_dir, 'config', 'config.yaml')
with open(config_path, 'r', encoding='utf-8') as f:
    config = yaml.safe_load(f)

# ≈öcie≈ºka do najlepszego modelu
model_path = os.path.join(base_dir, config['paths']['models_dir'], 'best_model.zip')

# Utw√≥rz katalogi na wyniki
output_dir = os.path.join(base_dir, 'logs', 'Analyze_model_extended')
conv_viz_dir = os.path.join(output_dir, 'conv_visualizations')
viewport_dir = os.path.join(output_dir, 'viewports')
action_probs_dir = os.path.join(output_dir, 'action_probs')
heatmap_dir = os.path.join(output_dir, 'attention_heatmaps')
lstm_dir = os.path.join(output_dir, 'lstm_analysis')
uncertainty_dir = os.path.join(output_dir, 'uncertainty_analysis')
confusion_dir = os.path.join(output_dir, 'confusion_matrix')
temporal_dir = os.path.join(output_dir, 'temporal_patterns')
critical_dir = os.path.join(output_dir, 'critical_moments')
feature_dir = os.path.join(output_dir, 'feature_importance')
bottleneck_dir = os.path.join(output_dir, 'bottleneck_analysis')

for dir_path in [output_dir, conv_viz_dir, viewport_dir, action_probs_dir, 
                 heatmap_dir, lstm_dir, uncertainty_dir, confusion_dir,
                 temporal_dir, critical_dir, feature_dir, bottleneck_dir]:
    os.makedirs(dir_path, exist_ok=True)

# Za≈Çaduj model RecurrentPPO
print("="*80)
print("üöÄ EXTENDED MODEL ANALYSIS")
print("="*80)
print("\n≈Åadowanie modelu...")
model = RecurrentPPO.load(model_path)
policy = model.policy
features_extractor = policy.features_extractor

print(f"\n=== Informacje o modelu ===")
print(f"CNN channels: {config['model']['convlstm']['cnn_channels']}")
print(f"Bottleneck dims: {config['model']['convlstm'].get('cnn_bottleneck_dims', 'N/A')}")
print(f"CNN output dim: {config['model']['convlstm'].get('cnn_output_dim', 'N/A')}")
print(f"Scalar hidden dims: {config['model']['convlstm']['scalar_hidden_dims']}")
print(f"Features dim: {config['model']['policy_kwargs']['features_extractor_kwargs']['features_dim']}")
print(f"LSTM hidden size: {config['model']['policy_kwargs']['lstm_hidden_size']}")
print(f"LSTM layers: {config['model']['policy_kwargs']['n_lstm_layers']}")
print(f"Actor network: {config['model']['policy_kwargs']['net_arch']['pi']}")
print(f"Critic network: {config['model']['policy_kwargs']['net_arch']['vf']}")

# Przygotuj ≈õrodowisko
env = make_env(render_mode=None, grid_size=16)()

# Nazwy akcji
action_names = ['lewo', 'prosto', 'prawo']

print("\n" + "="*80)
print("=== ROZPOCZƒòCIE ROZSZERZONEJ ANALIZY ===")
print("="*80)

# ===================================================
# CZƒò≈öƒÜ 1: ANALIZA PODSTAWOWA
# ===================================================
print("\n[1/11] Analiza podstawowych stan√≥w, aktywacji i attention...")
action_probs_list, detailed_activations, layer_gradients, attention_heatmaps = analyze_basic_states(
    model=model,
    env=env,
    output_dirs={
        'conv_viz': conv_viz_dir,
        'viewport': viewport_dir,
        'action_probs': action_probs_dir,
        'heatmap': heatmap_dir
    },
    action_names=action_names,
    config=config
)

# ===================================================
# CZƒò≈öƒÜ 2: ANALIZA BOTTLENECK√ìW
# ===================================================
print("\n[2/11] Analiza bottleneck√≥w...")
bottleneck_report = analyze_bottlenecks(
    layer_gradients=layer_gradients,
    action_names=action_names,
    output_dir=output_dir
)

# ===================================================
# CZƒò≈öƒÜ 3: PRZEGLƒÑD AKTYWACJI
# ===================================================
print("\n[3/11] Generowanie wykres√≥w przeglƒÖdu aktywacji...")
plot_activation_overview(
    detailed_activations=detailed_activations,
    action_probs_list=action_probs_list,
    action_names=action_names,
    output_dirs={
        'main': output_dir,
        'action_probs': action_probs_dir
    }
)

# ===================================================
# CZƒò≈öƒÜ 4: ANALIZA LSTM MEMORY
# ===================================================
print("\n[4/11] Analiza LSTM memory...")
analyze_lstm_memory(
    model=model,
    env=env,
    output_dir=lstm_dir,
    action_names=action_names,
    config=config
)

# ===================================================
# CZƒò≈öƒÜ 5: CONFUSION MATRIX
# ===================================================
print("\n[5/11] Analiza Confusion Matrix...")
analyze_confusion_matrix(
    model=model,
    env=env,
    output_dir=confusion_dir,
    action_names=action_names,
    num_episodes=20
)

# ===================================================
# CZƒò≈öƒÜ 6: UNCERTAINTY ANALYSIS
# ===================================================
print("\n[6/11] Analiza Uncertainty...")
analyze_uncertainty(
    model=model,
    env=env,
    output_dir=uncertainty_dir,
    action_names=action_names,
    num_episodes=10
)

# ===================================================
# CZƒò≈öƒÜ 7: ANALIZA SPECJALIZACJI KANA≈Å√ìW
# ===================================================
print("\n[7/11] Analiza specjalizacji kana≈Ç√≥w CNN...")
analyze_channel_specialization(
    model=model,
    env=env,
    output_dir=conv_viz_dir,
    num_samples=50
)

# ===================================================
# CZƒò≈öƒÜ 8: TEMPORAL PATTERNS ANALYSIS
# ===================================================
print("\n[8/11] Analiza wzorc√≥w temporalnych (LSTM memory patterns)...")
analyze_temporal_patterns(
    model=model,
    env=env,
    output_dir=temporal_dir,
    action_names=action_names,
    num_episodes=20
)

# ===================================================
# CZƒò≈öƒÜ 9: CRITICAL MOMENTS ANALYSIS
# ===================================================
print("\n[9/11] Analiza krytycznych moment√≥w (near-death, food acquisition)...")
analyze_critical_moments(
    model=model,
    env=env,
    output_dir=critical_dir,
    action_names=action_names,
    num_episodes=30
)

# ===================================================
# CZƒò≈öƒÜ 10: FEATURE IMPORTANCE ANALYSIS
# ===================================================
print("\n[10/11] Analiza wa≈ºno≈õci cech (ablation study)...")
analyze_feature_importance(
    model=model,
    env=env,
    output_dir=feature_dir,
    action_names=action_names,
    num_samples=100
)

# ===================================================
# CZƒò≈öƒÜ 11: BOTTLENECK ARCHITECTURE ANALYSIS
# ===================================================
print("\n[11/11] Analiza architektury bottleneck...")
analyze_bottleneck_architecture(
    model=model,
    env=env,
    output_dir=bottleneck_dir,
    num_samples=100
)

env.close()

# ===================================================
# PODSUMOWANIE KO≈ÉCOWE
# ===================================================
print("\n" + "="*80)
print("=== ANALIZA ZAKO≈ÉCZONA ===")
print("="*80)
print(f"\nüìÇ Wa≈ºne pliki analizy:")
print(f"   {output_dir}/")
print(f"   ‚îú‚îÄ‚îÄ bottleneck_analysis.png                ‚ö†Ô∏è Analiza bottleneck√≥w")
print(f"   ‚îú‚îÄ‚îÄ bottleneck_report.csv                  üìä Raport bottleneck√≥w")
print(f"   ‚îú‚îÄ‚îÄ neuron_activations_overview.png        üß† PrzeglƒÖd aktywacji")
print(f"   ‚îú‚îÄ‚îÄ attention_heatmaps/                    üî• Attention heatmaps")
print(f"   ‚îú‚îÄ‚îÄ lstm_analysis/                         üß† Analiza LSTM memory")
print(f"   ‚îú‚îÄ‚îÄ confusion_matrix/                      üìä Confusion matrix")
print(f"   ‚îú‚îÄ‚îÄ uncertainty_analysis/                  üé≤ Uncertainty metrics")
print(f"   ‚îú‚îÄ‚îÄ temporal_patterns/                     üïê Wzorce temporalne")
print(f"   ‚îú‚îÄ‚îÄ critical_moments/                      ‚ö†Ô∏è Krytyczne momenty")
print(f"   ‚îú‚îÄ‚îÄ feature_importance/                    üéØ Wa≈ºno≈õƒá cech")
print(f"   ‚îî‚îÄ‚îÄ bottleneck_analysis/                   üîß Architektura bottleneck")

print("\n" + "="*80)
print("=== KLUCZOWE WYNIKI ===")
print("="*80)

print("\nüî• ATTENTION HEATMAPS:")
print("   - PokazujƒÖ kt√≥re regiony viewport sƒÖ najwa≈ºniejsze dla decyzji")
print("   - Czerwone obszary = wysoka uwaga modelu")
print("   - Sprawd≈∫ czy model patrzy na jedzenie, ≈õciany, czy w≈Çasne cia≈Ço")

print("\nüß† LSTM MEMORY ANALYSIS:")
print("   - lstm_memory_evolution.png: jak zmienia siƒô pamiƒôƒá w czasie")
print("   - lstm_neurons_heatmap.png: aktywacja wszystkich neuron√≥w LSTM")
print("   - Sprawd≈∫ czy LSTM faktycznie wykorzystuje pamiƒôƒá d≈ÇugoterminowƒÖ")

print("\nüïê TEMPORAL PATTERNS:")
print("   - temporal_ngrams.png: najczƒôstsze sekwencje akcji (bigrams/trigrams)")
print("   - temporal_forgetting_curve.png: jak szybko LSTM zapomina")
print("   - temporal_entropy_evolution.png: niepewno≈õƒá decyzji w czasie")

print("\n‚ö†Ô∏è CRITICAL MOMENTS:")
print("   - critical_near_death.png: zachowanie modelu przed kolizjƒÖ")
print("   - critical_food_acquisition.png: efektywno≈õƒá zbierania jedzenia")
print("   - critical_tight_spaces.png: decyzje w ciasnych przestrzeniach")

print("\nüéØ FEATURE IMPORTANCE:")
print("   - feature_ablation_study.png: wp≈Çyw CNN vs scalars")
print("   - feature_gradient_importance.png: gradient-based importance")
print("   - feature_importance_results.csv: szczeg√≥≈Çowe wyniki")

print("\nüîß BOTTLENECK ARCHITECTURE:")
print("   - bottleneck_information_flow.png: przep≈Çyw informacji przez bottleneck")
print("   - bottleneck_path_comparison.png: main path vs residual path")
print("   - bottleneck_statistics.csv: statystyki architektury")

print("\n‚ö†Ô∏è  BOTTLENECKS:")
if bottleneck_report:
    high_severity = [b for b in bottleneck_report if b['severity'] == 'HIGH']
    medium_severity = [b for b in bottleneck_report if b['severity'] == 'MEDIUM']
    if high_severity:
        print(f"   - üî¥ WYSOKIE RYZYKO: {len(high_severity)} przypadk√≥w")
    if medium_severity:
        print(f"   - üü° ≈öREDNIE RYZYKO: {len(medium_severity)} przypadk√≥w")
    if not high_severity and not medium_severity:
        print("   - ‚úÖ Brak krytycznych bottleneck√≥w")

print("\n" + "="*80)
print("‚úÖ ROZSZERZONA ANALIZA ZAKO≈ÉCZONA!")
print("="*80)