import os
import sys
import yaml
import torch
import numpy as np
import shutil
from pathlib import Path
from sb3_contrib import RecurrentPPO

# Dodaj scripts do path
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
from model import make_env
from cnn import CustomFeaturesExtractor

# Import moduÅ‚Ã³w analizy
from utils.analyze_basic import analyze_basic_states, plot_activation_overview
from utils.analyze_gradients import analyze_bottlenecks, analyze_gradient_flow_detailed
from utils.analyze_cnn import analyze_cnn_layers
from utils.analyze_channels import analyze_conv_channels_detailed
from utils.analyze_lstm import analyze_lstm_comprehensive
from utils.analyze_performance import analyze_performance_metrics

# Wczytaj konfiguracjÄ™
base_dir = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
config_path = os.path.join(base_dir, 'config', 'config.yaml')
with open(config_path, 'r', encoding='utf-8') as f:
    config = yaml.safe_load(f)


def load_model_interactive():
    """
    ğŸ¯ Interaktywny wybÃ³r ÅºrÃ³dÅ‚a modelu dla analizy
    
    Returns:
        tuple: (model, source_name)
    """
    models_dir = os.path.join(base_dir, config['paths']['models_dir'])
    best_model_path = os.path.join(models_dir, 'best_model.zip')
    latest_model_path = os.path.join(models_dir, 'snake_ppo_model.zip')
    policy_path = os.path.join(base_dir, 'models', 'policy.pth')
    
    has_best = os.path.exists(best_model_path)
    has_latest = os.path.exists(latest_model_path)
    has_policy = os.path.exists(policy_path)
    
    print(f"\n{'='*70}")
    print(f"[MODEL SOURCE SELECTION FOR ANALYSIS]")
    print(f"{'='*70}")
    
    options = []
    
    if has_best:
        options.append(('1', 'best_model.zip', best_model_path))
        print(f"  [1] ğŸ† best_model.zip (najlepszy model z treningu)")
    
    if has_latest and latest_model_path != best_model_path:
        options.append(('2', 'snake_ppo_model.zip', latest_model_path))
        print(f"  [2] ğŸ“¦ snake_ppo_model.zip (ostatni checkpoint)")
    
    if has_policy:
        key = str(len(options) + 1)
        options.append((key, 'policy.pth', policy_path))
        print(f"  [{key}] ğŸ¯ policy.pth (tylko wagi sieci)")
    
    print(f"{'='*70}")
    
    if not options:
        raise FileNotFoundError("Nie znaleziono Å¼adnego modelu! SprawdÅº folder models/")
    
    if len(options) == 1:
        choice = options[0][0]
        print(f"\nâœ… Automatycznie wybrany: {options[0][1]}\n")
    else:
        while True:
            choice = input(f"\nWybierz ÅºrÃ³dÅ‚o modelu [1-{len(options)}]: ").strip()
            if any(choice == opt[0] for opt in options):
                break
            print(f"âŒ NieprawidÅ‚owy wybÃ³r. Wybierz 1-{len(options)}.")
    
    selected = next(opt for opt in options if opt[0] == choice)
    source_name = selected[1]
    source_path = selected[2]
    
    print(f"\nğŸ¬ Åadowanie: {source_name}...")
    
    # ZaÅ‚aduj model
    if source_name == 'policy.pth':
        # StwÃ³rz env do sprawdzenia observation_space
        temp_env = make_env(render_mode=None, grid_size=8)()
        
        # StwÃ³rz pusty model
        policy_kwargs = config['model']['policy_kwargs'].copy()
        policy_kwargs['features_extractor_class'] = CustomFeaturesExtractor
        
        model = RecurrentPPO(
            config['model']['policy'],
            temp_env,
            learning_rate=0.0001,
            n_steps=config['model']['n_steps'],
            batch_size=config['training']['batch_size'],
            n_epochs=config['model']['n_epochs'],
            gamma=config['model']['gamma'],
            gae_lambda=config['model']['gae_lambda'],
            clip_range=config['model']['clip_range'],
            ent_coef=config['model']['ent_coef'],
            vf_coef=config['model']['vf_coef'],
            policy_kwargs=policy_kwargs,
            verbose=0,
            device=config['model']['device']
        )
        
        # ZaÅ‚aduj wagi
        state_dict = torch.load(source_path, map_location=config['model']['device'])
        model.policy.load_state_dict(state_dict)
        
        temp_env.close()
        print(f"âœ… ZaÅ‚adowano policy.pth\n")
    else:
        model = RecurrentPPO.load(source_path)
        print(f"âœ… ZaÅ‚adowano {source_name}\n")
    
    return model, source_name


# ÅšcieÅ¼ka do najlepszego modelu (dla backward compatibility)
model_path = os.path.join(base_dir, config['paths']['models_dir'], 'best_model.zip')

# UtwÃ³rz katalogi na wyniki
output_dir = os.path.join(base_dir, 'logs', 'Analyze_model')

# âš ï¸ WAÅ»NE: WyczyÅ›Ä‡ poprzednie wyniki przed rozpoczÄ™ciem
if os.path.exists(output_dir):
    print(f"ğŸ—‘ï¸  Czyszczenie poprzednich wynikÃ³w z: {output_dir}")
    shutil.rmtree(output_dir)
    print("   âœ“ Katalog wyczyszczony")

# UtwÃ³rz strukturÄ™ katalogÃ³w
subdirs = {
    'main': os.path.join(output_dir, '01_basic_analysis'),
    'conv_viz': os.path.join(output_dir, '01_basic_analysis', 'conv_visualizations'),
    'viewport': os.path.join(output_dir, '01_basic_analysis', 'viewports'),
    'heatmap': os.path.join(output_dir, '01_basic_analysis', 'attention_heatmaps'),
    'cnn': os.path.join(output_dir, '02_cnn_layers'),
    'gradients': os.path.join(output_dir, '03_gradient_flow'),
    'lstm': os.path.join(output_dir, '04_lstm_memory'),
    'performance': os.path.join(output_dir, '05_performance')
}

for dir_path in subdirs.values():
    os.makedirs(dir_path, exist_ok=True)

# ZaÅ‚aduj model RecurrentPPO
print("="*80)
print("ğŸš€ MODEL ANALYSIS")
print("="*80)

# ğŸ¯ INTERAKTYWNY WYBÃ“R MODELU
model, source_name = load_model_interactive()

print(f"\nğŸ“Œ Analyzing model from: {source_name}")
print("\nÅadowanie modelu...")
policy = model.policy
features_extractor = policy.features_extractor

print(f"\n=== Informacje o modelu ===")
print(f"CNN channels: {config['model']['convlstm']['cnn_channels']}")
print(f"Bottleneck dims: {config['model']['convlstm'].get('cnn_bottleneck_dims', 'N/A')}")
print(f"CNN output dim: {config['model']['convlstm'].get('cnn_output_dim', 'N/A')}")
print(f"Scalar hidden dims: {config['model']['convlstm']['scalar_hidden_dims']}")
print(f"Features dim: {config['model']['policy_kwargs']['features_extractor_kwargs']['features_dim']}")
print(f"LSTM hidden size: {config['model']['policy_kwargs']['lstm_hidden_size']}")
print(f"LSTM layers: {config['model']['policy_kwargs']['n_lstm_layers']}")
print(f"Actor network: {config['model']['policy_kwargs']['net_arch']['pi']}")
print(f"Critic network: {config['model']['policy_kwargs']['net_arch']['vf']}")

# Przygotuj Å›rodowisko
env = make_env(render_mode=None, grid_size=16)()

# Nazwy akcji
action_names = ['lewo', 'prosto', 'prawo']

print("\n" + "="*80)
print("=== ROZPOCZÄ˜CIE ANALIZY ===")
print("="*80)

# ===================================================
# CZÄ˜ÅšÄ† 1: ANALIZA PODSTAWOWA (viewport, activations, attention)
# ===================================================
print("\n[1/6] ğŸ“Š Analiza podstawowa: aktywacje, viewport, attention...")
action_probs_list, detailed_activations, layer_gradients, attention_heatmaps = analyze_basic_states(
    model=model,
    env=env,
    output_dirs=subdirs,  # âœ… POPRAWKA: output_dirs zamiast output_dir
    action_names=action_names,
    config=config
)

plot_activation_overview(
    detailed_activations=detailed_activations,
    action_probs_list=action_probs_list,
    action_names=action_names,
    output_dirs=subdirs  # âœ… POPRAWKA: output_dirs zamiast output_dir
)

# ===================================================
# CZÄ˜ÅšÄ† 2: ANALIZA CNN (channels, saturation, specialization)
# ===================================================
print("\n[2/6] ğŸ” Analiza warstw CNN (channels, saturation, specialization)...")
analyze_cnn_layers(
    model=model,
    env=env,
    output_dir=subdirs['cnn'],
    num_samples=100
)

# ===================================================
# CZÄ˜ÅšÄ† 2.5: SZCZEGÃ“ÅOWA ANALIZA KANAÅÃ“W CNN
# ===================================================
print("\n[2.5/6] ğŸ”¬ SzczegÃ³Å‚owa analiza kanaÅ‚Ã³w Conv1/Conv2...")
analyze_conv_channels_detailed(
    model=model,
    env=env,
    output_dir=subdirs['cnn'],
    num_samples=100
)

# ===================================================
# CZÄ˜ÅšÄ† 3: ANALIZA GRADIENTÃ“W (bottlenecks, gradient flow)
# ===================================================
print("\n[3/6] ğŸŒŠ Analiza przepÅ‚ywu gradientÃ³w...")
bottleneck_report = analyze_bottlenecks(
    layer_gradients=layer_gradients,
    action_names=action_names,
    output_dir=subdirs['gradients']
)

analyze_gradient_flow_detailed(
    model=model,
    env=env,
    output_dir=subdirs['gradients'],
    num_samples=50
)

# ===================================================
# CZÄ˜ÅšÄ† 4: ANALIZA LSTM (memory, temporal patterns, forgetting)
# ===================================================
print("\n[4/6] ğŸ§  Kompleksowa analiza LSTM...")
analyze_lstm_comprehensive(
    model=model,
    env=env,
    output_dir=subdirs['lstm'],
    action_names=action_names,
    config=config,
    num_episodes=20
)

# ===================================================
# CZÄ˜ÅšÄ† 5: ANALIZA WYDAJNOÅšCI (critical moments, feature importance, uncertainty)
# ===================================================
print("\n[5/6] ğŸ¯ Analiza wydajnoÅ›ci i zachowaÅ„ modelu...")
analyze_performance_metrics(
    model=model,
    env=env,
    output_dir=subdirs['performance'],
    action_names=action_names,
    num_episodes=30,
    num_samples=100
)

env.close()

# ===================================================
# PODSUMOWANIE KOÅƒCOWE
# ===================================================
print("\n" + "="*80)
print("=== ANALIZA ZAKOÅƒCZONA ===")
print("="*80)
print("\nğŸ“‚ Wyniki analizy zapisane w:")
print(f"   {output_dir}/")
print(f"   â”œâ”€â”€ 01_basic_analysis/         ğŸ“Š Podstawowe aktywacje i viewport")
print(f"   â”œâ”€â”€ 02_cnn_layers/             ğŸ” Analiza warstw CNN + szczegÃ³Å‚owa analiza kanaÅ‚Ã³w")
print(f"   â”œâ”€â”€ 03_gradient_flow/          ğŸŒŠ PrzepÅ‚yw gradientÃ³w")
print(f"   â”œâ”€â”€ 04_lstm_memory/            ğŸ§  PamiÄ™Ä‡ i wzorce temporalne")
print(f"   â””â”€â”€ 05_performance/            ğŸ¯ WydajnoÅ›Ä‡ i zachowania")

print("\n" + "="*80)
print("=== KLUCZOWE WYNIKI ===")
print("="*80)

print(f"\nğŸ“Œ Analyzed model: {source_name}")

print("\nğŸ“Š BASIC ANALYSIS:")
print("   - neuron_activations_overview.png: RMS aktywacji CNN vs Scalars")
print("   - attention_heatmaps/: gdzie model skupia uwagÄ™")
print("   - viewports/: wizualizacja stanÃ³w gry")

print("\nğŸ” CNN LAYERS:")
print("   - channel_specialization.png: aktywne vs martwe kanaÅ‚y")
print("   - activation_saturation.png: saturacja GELU")
print("   - conv_visualizations/: filtry CNN dla kaÅ¼dej warstwy")
print("   - all_conv_channels_analysis.png: ğŸ†• szczegÃ³Å‚owa analiza kaÅ¼dego kanaÅ‚u")

print("\nğŸŒŠ GRADIENT FLOW:")
print("   - bottleneck_analysis_split.png: bottlenecki per sekcja")
print("   - bottleneck_gradient_heatmap.png: flow przez warstwy")
print("   - gradient_flow_detailed.png: vanishing/explosion")

print("\nğŸ§  LSTM MEMORY:")
print("   - lstm_memory_evolution.png: ewolucja pamiÄ™ci")
print("   - lstm_neurons_heatmap.png: aktywacja neuronÃ³w")
print("   - temporal_forgetting_curve.png: jak szybko zapomina")
print("   - temporal_ngrams.png: sekwencje akcji")

print("\nğŸ¯ PERFORMANCE:")
print("   - critical_near_death.png: zachowanie przed kolizjÄ…")
print("   - critical_food_acquisition.png: efektywnoÅ›Ä‡ zbierania")
print("   - feature_ablation_study.png: wpÅ‚yw CNN vs scalars")
print("   - confusion_matrix.png: porÃ³wnanie z heurystykÄ…")
print("   - uncertainty_analysis.png: pewnoÅ›Ä‡ decyzji")

print("\nâš ï¸ BOTTLENECKS:")
if bottleneck_report:
    high_severity = [b for b in bottleneck_report if b['severity'] == 'HIGH']
    medium_severity = [b for b in bottleneck_report if b['severity'] == 'MEDIUM']
    if high_severity:
        print(f"   - ğŸ”´ WYSOKIE RYZYKO: {len(high_severity)} przypadkÃ³w")
    if medium_severity:
        print(f"   - ğŸŸ¡ ÅšREDNIE RYZYKO: {len(medium_severity)} przypadkÃ³w")
    if not high_severity and not medium_severity:
        print("   - âœ… Brak krytycznych bottleneckÃ³w")

print("\n" + "="*80)
print("âœ… ANALIZA ZAKOÅƒCZONA!")
print("="*80)