"""
test_utils.py - ğŸ¯ WspÃ³lne funkcje dla skryptÃ³w testowania (test_snake_model.py, make_gif.py)
Unika duplikacji kodu miÄ™dzy skryptami
"""
import os
import yaml
import torch
from pathlib import Path
from stable_baselines3 import PPO
from model import make_env
from cnn import CustomFeaturesExtractor


def select_visual_style():
    """
    ğŸ¨ Interaktywny wybÃ³r stylu wizualnego
    
    Returns:
        str: Nazwa stylu ('classic', 'modern', 'realistic')
    """
    print(f"\n{'='*70}")
    print(f"[VISUAL STYLE SELECTION]")
    print(f"{'='*70}")
    print(f"  [1] ğŸŸ© Classic   - Prosty retro styl (szybki)")
    print(f"  [2] ğŸ® Modern    - Nowoczesny z gradientami i animacjami")
    print(f"  [3] ğŸ Realistic - Realistyczny z teksturami (wolniejszy)")
    print(f"{'='*70}")
    
    while True:
        choice = input(f"\nWybierz styl [1-3] (default: Classic): ").strip()
        
        if choice == '' or choice == '1':
            print(f"âœ… Wybrany styl: Classic\n")
            return 'classic'
        elif choice == '2':
            print(f"âœ… Wybrany styl: Modern\n")
            return 'modern'
        elif choice == '3':
            print(f"âœ… Wybrany styl: Realistic\n")
            return 'realistic'
        else:
            print("âŒ NieprawidÅ‚owy wybÃ³r. Wybierz 1-3.")


def select_grid_size_interactive(default_size=8):
    """
    ğŸ¯ Interaktywny wybÃ³r rozmiaru siatki
    
    Returns:
        int: Wybrany rozmiar siatki
    """
    print(f"\n{'='*70}")
    print(f"[GRID SIZE SELECTION]")
    print(f"{'='*70}")
    print(f"  [1] ğŸŸ© 8x8   (Easy - MaÅ‚a siatka)")
    print(f"  [2] ğŸŸ¦ 12x12 (Medium)")
    print(f"  [3] ğŸŸ¨ 16x16 (Hard - DuÅ¼a siatka)")
    print(f"  [4] ğŸŸª Custom (WÅ‚asny rozmiar)")
    print(f"{'='*70}")
    
    while True:
        choice = input(f"\nWybierz rozmiar siatki [1-4] (default: {default_size}x{default_size}): ").strip()
        
        if choice == '' or choice == '0':
            print(f"âœ… UÅ¼ywam domyÅ›lnego: {default_size}x{default_size}\n")
            return default_size
        elif choice == '1':
            return 8
        elif choice == '2':
            return 12
        elif choice == '3':
            return 16
        elif choice == '4':
            while True:
                try:
                    custom = input("Podaj rozmiar siatki (4-32): ").strip()
                    custom_size = int(custom)
                    if 4 <= custom_size <= 32:
                        return custom_size
                    else:
                        print("âŒ Rozmiar musi byÄ‡ miÄ™dzy 4 a 32.")
                except ValueError:
                    print("âŒ NieprawidÅ‚owa wartoÅ›Ä‡. Podaj liczbÄ™.")
        else:
            print("âŒ NieprawidÅ‚owy wybÃ³r. Wybierz 1-4 lub Enter dla domyÅ›lnego.")


def load_model_interactive(model_path, policy_path, base_dir):
    """
    ğŸ¯ Interaktywny wybÃ³r ÅºrÃ³dÅ‚a modelu
    
    Args:
        model_path: ÅšcieÅ¼ka do modelu
        policy_path: ÅšcieÅ¼ka do policy.pth
        base_dir: ÅšcieÅ¼ka bazowa projektu
    
    Returns:
        tuple: (model, source_name)
    """
    base_dir = Path(base_dir)
    has_full_model = os.path.exists(model_path)
    has_best_model = os.path.exists(base_dir / 'models' / 'best_model.zip')
    has_policy = os.path.exists(policy_path)
    
    print(f"\n{'='*70}")
    print(f"[MODEL SOURCE SELECTION]")
    print(f"{'='*70}")
    
    options = []
    
    if has_best_model:
        options.append(('1', 'best_model.zip', base_dir / 'models' / 'best_model.zip'))
        print(f"  [1] ğŸ† best_model.zip (najlepszy model z treningu)")
    
    if has_full_model and str(model_path) != str(base_dir / 'models' / 'best_model.zip'):
        options.append(('2', 'snake_ppo_model.zip', model_path))
        print(f"  [2] ğŸ“¦ snake_ppo_model.zip (ostatni checkpoint)")
    
    if has_policy:
        key = str(len(options) + 1)
        options.append((key, 'policy.pth', policy_path))
        print(f"  [{key}] ğŸ¯ policy.pth (tylko wagi sieci)")
    
    print(f"{'='*70}")
    
    if not options:
        raise FileNotFoundError("Nie znaleziono Å¼adnego modelu! SprawdÅº folder models/")
    
    if len(options) == 1:
        choice = options[0][0]
        print(f"\nâœ… Automatycznie wybrany: {options[0][1]}\n")
    else:
        while True:
            choice = input("\nWybierz ÅºrÃ³dÅ‚o modelu [1-{}]: ".format(len(options))).strip()
            if any(choice == opt[0] for opt in options):
                break
            print(f"âŒ NieprawidÅ‚owy wybÃ³r. Wybierz 1-{len(options)}.")
    
    selected = next(opt for opt in options if opt[0] == choice)
    source_name = selected[1]
    source_path = selected[2]
    
    print(f"\nğŸ¬ Åadowanie: {source_name}...")
    
    # ZaÅ‚aduj model
    if source_name == 'policy.pth':
        # Wczytaj config
        config_path = base_dir / 'config' / 'config.yaml'
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        # StwÃ³rz env do sprawdzenia observation_space
        temp_env = make_env(render_mode=None, grid_size=8)()
        
        # StwÃ³rz pusty model
        policy_kwargs = config['model']['policy_kwargs'].copy()
        policy_kwargs['features_extractor_class'] = CustomFeaturesExtractor
        
        model = PPO(
            config['model']['policy'],
            temp_env,
            learning_rate=0.0001,
            n_steps=config['model']['n_steps'],
            batch_size=config['training']['batch_size'],
            n_epochs=config['model']['n_epochs'],
            gamma=config['model']['gamma'],
            gae_lambda=config['model']['gae_lambda'],
            clip_range=config['model']['clip_range'],
            ent_coef=config['model']['ent_coef'],
            vf_coef=config['model']['vf_coef'],
            policy_kwargs=policy_kwargs,
            verbose=0,
            device=config['model']['device']
        )
        
        # ZaÅ‚aduj wagi
        state_dict = torch.load(source_path, map_location=config['model']['device'])
        model.policy.load_state_dict(state_dict)
        
        temp_env.close()
        print(f"âœ… ZaÅ‚adowano policy.pth\n")
    else:
        model = PPO.load(source_path)
        print(f"âœ… ZaÅ‚adowano {source_name}\n")
    
    return model, source_name
